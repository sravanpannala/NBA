{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from nbafuns import *\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn_evaluation import plot\n",
    "\n",
    "data_DIR = \"../data/rapm/\"\n",
    "misc_DIR = \"../data/misc/\"\n",
    "model_path = \"../data/models/\"\n",
    "pbp_DIR = \"../data/pbpdata/\"\n",
    "fig_DIR = \"../figs/analysis/\"\n",
    "\n",
    "team_dict, team_list  = get_teams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample in-game data (replace with your actual play-by-play data)\n",
    "def load_ingame_data():\n",
    "    # Simulating play-by-play data\n",
    "    data = pd.read_parquet(data_DIR + \"NBA_rapm_possessions_odds_2017_2024.parquet\")\n",
    "    return data\n",
    "\n",
    "# Feature engineering\n",
    "def engineer_features(df):\n",
    "    # Add useful derived features\n",
    "    df[\"spread_mod\"] = df[\"spread\"]*(df[\"secs\"]/ 2880)**4\n",
    "    df['time_remaining_pct'] = df['secs'] / 2880\n",
    "    df['points_per_second'] = df['margin'] / (2880 - df['secs']).clip(lower=1)\n",
    "    df['is_endgame'] = (df['secs'] < 300) & (df['period'] == 4).astype(int)\n",
    "    \n",
    "    features = [\n",
    "        'margin',\n",
    "        'secs',\n",
    "        'spread_mod',\n",
    "        'period',\n",
    "        'homeball',\n",
    "        # 'time_remaining_pct',\n",
    "        # 'points_per_second',\n",
    "        # 'spread_mod',\n",
    "        'is_endgame',\n",
    "    ]\n",
    "    return df, features\n",
    "\n",
    "def prepare_data(df, features):\n",
    "    X = df[features]\n",
    "    y = df['win']\n",
    "    \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def train_catboost_model(X_train, X_test, y_train, y_test):\n",
    "    # Define categorical features\n",
    "    cat_features = ['period', 'homeball', 'is_endgame']\n",
    "    \n",
    "    # Create data pools\n",
    "    train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "    test_pool = Pool(X_test, y_test, cat_features=cat_features)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        loss_function='Logloss',\n",
    "        # eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        use_best_model=True,\n",
    "        task_type=\"GPU\",\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        early_stopping_rounds=50\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Predictions\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Log Loss: {logloss:.4f}\")\n",
    "    \n",
    "    return y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process data\n",
    "df = load_ingame_data()\n",
    "df, features = engineer_features(df)\n",
    "X_train, X_test, y_train, y_test = prepare_data(df, features)\n",
    "\n",
    "# Train model\n",
    "model = train_catboost_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate\n",
    "predictions = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': model.get_feature_importance()\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the probability to belonging to the positive class\n",
    "prob_positive = probas[:, 1]\n",
    "# data frame with probabilities and actual labels\n",
    "df = pd.DataFrame({'prob': prob_positive, 'actual': y_test})\n",
    "# bin probabilities\n",
    "df['prob_bin'] = pd.cut(df.prob, bins=np.arange(0, 1.1, 0.1))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('prob_bin').actual.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_true, probs, names, ax=None):\n",
    "    \"\"\"Plot calibration curve\n",
    "    \"\"\"\n",
    "    # if ax is None:\n",
    "    #     fig, ax = plt.subplots(1,1)\n",
    "    #     fig.set_figheight(4)\n",
    "    #     fig.set_figwidth(6)\n",
    "    #     fig.set_dpi(150)\n",
    "\n",
    "    plot.calibration_curve(y_true, probs, names)#, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(y_test)\n",
    "probs = list(prob_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "probs = [data.prob.values]\n",
    "y_true = [data.actual.values]\n",
    "names = [\"Catboost V2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_true, probs, names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(6)\n",
    "fig.set_dpi(150)\n",
    "_ = plot.scores_distribution(data.prob.values, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameids = df.gid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# gid = gameids[i]\n",
    "gid = gameids[np.random.randint(0,len(gameids))]\n",
    "dfp = df.query(f\"gid == '{gid}'\")\n",
    "ypred = model.predict_proba(dfp[features])\n",
    "dfp[\"wp\"] = ypred[:,1]\n",
    "p = (\n",
    "    ggplot(dfp)\n",
    "    + aes(x=\"secs\",y=\"wp\")\n",
    "    + geom_point()\n",
    "    + geom_line()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + scale_x_reverse()\n",
    "    + theme_idv\n",
    ")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dav-ub9Z_EQq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
