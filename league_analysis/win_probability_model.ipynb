{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from nbafuns import *\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Only this extra line of code is required to use oneDNN Graph\n",
    "torch.jit.enable_onednn_fusion(True)\n",
    "torch.autograd.detect_anomaly = False\n",
    "torch.autograd.profiler.emit_nvtx = False \n",
    "torch.autograd.profiler.profile = False\n",
    "torch.autograd.gradcheck = False\n",
    "torch.autograd.gradgradcheck = False\n",
    "\n",
    "data_DIR = \"../data/rapm/\"\n",
    "misc_DIR = \"../data/misc/\"\n",
    "model_path = \"../data/models/\"\n",
    "pbp_DIR = \"../data/pbpdata/\"\n",
    "fig_DIR = \"../figs/analysis/\"\n",
    "\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads possessions with odds\n",
    "dfw = pd.read_parquet(data_DIR + \"NBA_rapm_possessions_odds_2017_2024.parquet\")\n",
    "len(dfw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "rr = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfw[['margin', 'spread', 'secs']].values\n",
    "y = dfw['win'].values\n",
    "\n",
    "# sample the data\n",
    "test_gid = dfw['gid'].sample(frac=0.8, random_state=rr).to_list()\n",
    "dfw11 = dfw[dfw['gid'].isin(test_gid)]\n",
    "# dfw12 = dfw11.query(\"secs <=120\")\n",
    "# for i in range(4):\n",
    "#     dfw11  = pd.concat([dfw11,dfw12])\n",
    "dfw1 = dfw11\n",
    "dfw2 = dfw[dfw['gid'].isin(test_gid)]\n",
    "\n",
    "# scale the data\n",
    "scaler = MinMaxScaler()\n",
    "smodel = scaler.fit(X)\n",
    "Xs = smodel.transform(X)\n",
    "X_train =  smodel.transform(dfw1[['margin', 'spread', 'secs']].values)\n",
    "y_train = dfw1['win'].values\n",
    "X_test =  smodel.transform(dfw2[['margin', 'spread', 'secs']].values)\n",
    "y_test = dfw2['win'].values\n",
    "\n",
    "# convert to tensors\n",
    "inputs = torch.FloatTensor(Xs)\n",
    "labels = torch.FloatTensor(y).unsqueeze(1)\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "y_test = torch.FloatTensor(y_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_weights(h1=12,h2=12,num_epochs=100,des=\"base\"):\n",
    "    torch.manual_seed(rr)\n",
    "    # Initialize the model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(3,h1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1,h2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h2,1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    criterion = nn.BCELoss()\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(),lr=1e-3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    losses = []\n",
    "    for epoch in trange(num_epochs,desc=\"epochs\",leave=False):\n",
    "        model.train()\n",
    "        # optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    pred = model.forward(inputs)\n",
    "    x_out = dfw[\"secs\"].values\n",
    "    y_out = pred.detach().numpy()\n",
    "    fig,ax=plt.subplots(1,1,figsize=(5,4))\n",
    "    ax.plot(range(num_epochs),losses)\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(f\"Layer 1: {h1:02d} Layer2: {h2:02d} Epochs: {num_epochs:03d}\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./testing/weights_{h1:02d}_{h2:02d}_{num_epochs:03d}_{des}_losses.png\",dpi=200)\n",
    "    fig,ax=plt.subplots(1,1,figsize=(5,4))\n",
    "    ax.plot(x_out,y_out,\"x\")\n",
    "    ax.set_xlim((3000,0))\n",
    "    ax.set_xlabel(\"Time Remaining in Game [s]\")\n",
    "    ax.set_ylabel(\"Win Probability\")\n",
    "    ax.set_title(f\"Layer 1: {h1:02d} Layer2: {h2:02d} Epochs: {num_epochs:03d}\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./testing/weights_{h1:02d}_{h2:02d}_{num_epochs:03d}_{des}_res.png\",dpi=200)\n",
    "    torch.save(model, f\"./testing/model_{h1:02d}_{h2:02d}_{num_epochs:03d}_{des}.pt\")\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, losses = try_weights(h1=12,h2=12,num_epochs=50,des=\"opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h1 in trange(12,25,4, desc=\"h1\"):\n",
    "    for h2 in trange(h1,int(h1/2)-1,-4, desc=\"h2\", leave=False): \n",
    "        try_weights(h1=h1,h2=h2,num_epochs=400,des=\"opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.get_all_sharing_strategies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for efficient batching\n",
    "bs=8\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "batch_size = int(len(dataset)/bs)+1\n",
    "world_size = 4\n",
    "rank = 0\n",
    "num_epochs = 50\n",
    "os.environ['MASTER_ADDR'] = '192.168.1.3'\n",
    "os.environ['MASTER_PORT'] = '8888'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_weights_dist(h1=12,h2=12,batch_size=batch_size,rank=rank, world_size=world_size):\n",
    "    torch.manual_seed(rr)\n",
    "    # Initialize the model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(3,h1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1,h2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h2,1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    # Distributed\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "    # construct DDP model\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    # loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(),lr=1e-3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    batch_size = batch_size\n",
    "    sampler = DistributedSampler(dataset,num_replicas=world_size,rank=rank)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs,desc=\"epochs\"):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            inputs_batch,labels_batch = batch\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 10 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try_weights_dist(h1=12,h2=12,batch_size=batch_size,rank=rank, world_size=world_size)\n",
    "mp.spawn(try_weights_dist,nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)#,num_workers=1)\n",
    "num_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h1 in trange(12,13,4, desc=\"h1\"):\n",
    "    for h2 in trange(h1,int(h1/2)-1,-4, desc=\"h2\"): \n",
    "        try_weights(h1=h1,h2=h2,num_epochs=50,bs=4,des=\"opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batches No Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_weights(h1=12,h2=12,num_epochs=100,bs=4,des=\"base\",rank=rank, world_size=world_size):\n",
    "    torch.manual_seed(rr)\n",
    "    # Initialize the model\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(3,h1),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h1,h2),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(h2,1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    # Distributed\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "    # Create DataLoader for efficient batching\n",
    "    dataset = TensorDataset(inputs, labels)\n",
    "    batch_size = int(len(dataset)/bs)+1\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)#,num_workers=1)\n",
    "    # loss function\n",
    "    criterion = nn.BCELoss()\n",
    "    # optimizer = torch.optim.RMSprop(model.parameters(),lr=1e-3)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "    losses = []\n",
    "    for epoch in trange(num_epochs,desc=\"epochs\"):\n",
    "        model.train()\n",
    "        for i in trange(len(dataloader),desc=\"batches\", leave=False):\n",
    "            inputs_batch,labels_batch = next(iter(dataloader))\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "            outputs = model(inputs_batch)\n",
    "            loss = criterion(outputs, labels_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            if i % 10 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f'Epoch {epoch}/{num_epochs}, Loss: {loss.item()}')\n",
    "    \n",
    "    pred = model.forward(inputs)\n",
    "    x_out = dfw[\"secs\"].values\n",
    "    y_out = pred.detach().numpy()\n",
    "    fig,ax=plt.subplots(1,1,figsize=(5,4))\n",
    "    ax.plot(range(num_epochs*bs),losses)\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_title(f\"Layer 1: {h1:02d} Layer2: {h2:02d} Epochs: {num_epochs:03d}\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./testing/weights_{h1:02d}_{h2:02d}_{num_epochs:03d}_{des}_losses.png\",dpi=200)\n",
    "    fig,ax=plt.subplots(1,1,figsize=(5,4))\n",
    "    ax.plot(x_out,y_out,\"x\")\n",
    "    ax.set_xlim((3000,0))\n",
    "    ax.set_xlabel(\"Time Remaining in Game [s]\")\n",
    "    ax.set_ylabel(\"Win Probability\")\n",
    "    ax.set_title(f\"Layer 1: {h1:02d} Layer2: {h2:02d} Epochs: {num_epochs:03d}\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"./testing/weights_{h1:02d}_{h2:02d}_{num_epochs:03d}_batch{batch_size:02d}_{des}_res.png\",dpi=200)\n",
    "    torch.save(model, f\"./testing/model_{h1:02d}_{h2:02d}_{num_epochs:03d}_batch{batch_size:02d}_{des}.pt\")\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h1 in trange(12,13,4, desc=\"h1\"):\n",
    "    for h2 in trange(h1,int(h1/2)-1,-4, desc=\"h2\"): \n",
    "        try_weights(h1=h1,h2=h2,num_epochs=50,bs=4,des=\"opt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgfdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(inputs)\n",
    "x_out = dfw[\"secs\"].values\n",
    "y_out = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw[\"win_prob\"] = y_out\n",
    "games  = dfw[\"gid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dict, team_list  = get_teams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line =  -15\n",
    "dfw1 = dfw.query(f\"spread == {line}\")\n",
    "p = (\n",
    "    ggplot(dfw1)\n",
    "    + aes(x=\"secs\",y=\"win_prob\",group=\"gid\")\n",
    "    + geom_smooth(se=False,size=0.2)\n",
    "    + scale_x_reverse()\n",
    "    + scale_y_continuous(labels=percent_format())\n",
    "    + theme_xkcd(base_size=16,stroke_size=0.1)\n",
    "    + labs(title = f\"{team_dict[dfw1[\"tida\"].iloc[0]]} vs {team_dict[dfw1[\"tidh\"].iloc[0]]}\")\n",
    ")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sadasdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_eval = model.forward(X_test)\n",
    "    loss = criterion(y_eval,y_test)\n",
    "print(loss)\n",
    "torch.save(model.state_dict(), model_path +\"win_prob_dict_1\")\n",
    "torch.save(model, model_path +\"win_prob_1.pt\")\n",
    "# Model class must be defined somewhere\n",
    "# model1 = torch.load( model_path +\"win_prob_1.pt\", weights_only=False)\n",
    "# model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = \"nba\"\n",
    "margin = -5 # from the perspective of the team with the ball\n",
    "seconds_remaining = 60 # This is time remaining at the start of the possession\n",
    "pre_game_win_prob = 0.55 # 55% to win pregame\n",
    "end_of_possession_seconds_remaining = 45 # seconds remaining at end of possession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.pbpstats.com/get-leverage/{league}/{margin}/{pre_game_win_prob}/{seconds_remaining}/{end_of_possession_seconds_remaining}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response_json = response.json()\n",
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print model's state_dict\n",
    "# print(\"Model's state_dict:\")\n",
    "# for param_tensor in model.state_dict():\n",
    "#     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# # Print optimizer's state_dict\n",
    "# print(\"Optimizer's state_dict:\")\n",
    "# for var_name in optimizer.state_dict():\n",
    "#     print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = PyTorchModel()\n",
    "# model1.load_state_dict(torch.load(model_path +\"win_prob_dict_1\", weights_only=True))\n",
    "# model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(num_epochs,desc=\"epochs\", leave=False):\n",
    "        y_pred = model.forward(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        losses.append(loss.detach().numpy())\n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f'Epoch {epoch}/{num_epochs}, Loss: {loss}')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dav-ub9Z_EQq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
