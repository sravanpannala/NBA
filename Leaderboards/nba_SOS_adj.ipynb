{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Adjust Offensive, Defensive and Net Ratings for Strength of Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from nbafuns import *\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid') \n",
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
    "\n",
    "team_data = pd.read_csv(\"../data/NBA_teams_database.csv\") \n",
    "teams_list = team_data[\"TeamID\"].tolist()\n",
    "team_dict1 = team_data.to_dict(orient=\"records\")\n",
    "teams_dict = {team[\"TeamID\"]:team[\"Team\"] for team in team_dict1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ratings Function:\n",
    "1. Reads Advanced Box Scores from csv file\n",
    "2. Groups two entries for a single game (team1 and team2)\n",
    "3. Splits columns for team1 and team2 for team1\n",
    "4. Splits columns for team1 and team2 for team2\n",
    "5. Combines the split data to get back two entries for single game with appropriate opposition information and stats\n",
    "6. Returns the combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(season=2023):\n",
    "    df1 = pd.read_csv(f\"./boxscores/NBA_BoxScores_Adv_{season}.csv\")\n",
    "    cols = [\"gameId\",\"teamName\",\"teamId\",\"offensiveRating\",\"defensiveRating\",\"netRating\",\"possessions\"]\n",
    "    df2 = df1[cols]\n",
    "    df2.iloc[:,2:]=df2.iloc[:,2:].astype(str)\n",
    "    df3 = df2.groupby(\"gameId\")[cols[1:]].agg(\", \".join).reset_index()\n",
    "    df4 = df3.copy()\n",
    "    df4[[\"team1\",\"team2\"]] = df3[\"teamName\"].str.split(\",\",expand=True)\n",
    "    df4[[\"tId1\",\"tId2\"]] = df3[\"teamId\"].str.split(\",\",expand=True)\n",
    "    df4[[\"ORtg1\",\"ORtg2\"]] = df3[\"offensiveRating\"].str.split(\",\",expand=True)\n",
    "    df4[[\"DRtg1\",\"DRtg2\"]] = df3[\"defensiveRating\"].str.split(\",\",expand=True)\n",
    "    df4[[\"NRtg1\",\"NRtg2\"]] = df3[\"netRating\"].str.split(\",\",expand=True)\n",
    "    df4[[\"poss1\",\"poss2\"]] = df3[\"possessions\"].str.split(\",\",expand=True)\n",
    "    df4 = df4.drop(columns=cols[1:])\n",
    "    df5 = df3.copy()\n",
    "    df5[[\"team2\",\"team1\"]] = df3[\"teamName\"].str.split(\",\",expand=True)\n",
    "    df5[[\"tId2\",\"tId1\"]] = df3[\"teamId\"].str.split(\",\",expand=True)\n",
    "    df5[[\"ORtg2\",\"ORtg1\"]] = df3[\"offensiveRating\"].str.split(\",\",expand=True)\n",
    "    df5[[\"DRtg2\",\"DRtg1\"]] = df3[\"defensiveRating\"].str.split(\",\",expand=True)\n",
    "    df5[[\"NRtg2\",\"NRtg1\"]] = df3[\"netRating\"].str.split(\",\",expand=True)\n",
    "    df5[[\"poss2\",\"poss1\"]] = df3[\"possessions\"].str.split(\",\",expand=True)\n",
    "    df5 = df5.drop(columns=cols[1:])\n",
    "    df6 = pd.concat([df4,df5]).sort_values(by=\"gameId\").reset_index(drop=True)\n",
    "    df6.iloc[:,5:]=df6.iloc[:,5:].astype(float)\n",
    "    df6.iloc[:,3:5]=df6.iloc[:,3:5].astype(int)\n",
    "    data1 = df6.copy()\n",
    "    stats = leaguegamelog.LeagueGameLog(player_or_team_abbreviation=\"T\",season=season,season_type_all_star=\"Regular Season\")\n",
    "    df10 = stats.get_data_frames()[0]\n",
    "    df10[\"HOME\"] = df10['MATCHUP'].str.contains(\"@\")\n",
    "    df10[\"tId1\"]= df10[\"TEAM_ID\"]\n",
    "    df10[\"gameId\"]= df10[\"GAME_ID\"]\n",
    "    df11 = df10[[\"gameId\",\"tId1\",\"HOME\"]].sort_values(by=\"gameId\").reset_index(drop=True)\n",
    "    df11[[\"gameId\",\"tId1\"]] = df11[[\"gameId\",\"tId1\"]].astype(int)\n",
    "    data = pd.merge(data1,df11)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Results Function\n",
    "1. Calculates Offensive, Defensive and Net Ratings from data\n",
    "2. Merges Regression results with data (combine adjusted and unadjusted ratings)\n",
    "3. Round all results\n",
    "4. Calculate SOS values\n",
    "5. Return results after cleaning and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(data,results_adj,intercept):\n",
    "    data[\"pts1\"] = data[\"ORtg1\"] * data[\"poss1\"]\n",
    "    data[\"pts2\"] = data[\"DRtg1\"] * data[\"poss1\"]\n",
    "    off_prior = data.groupby([\"tId1\"])[[\"poss1\",\"pts1\"]].agg(\"sum\").reset_index()\n",
    "    def_prior = data.groupby([\"tId1\"])[[\"poss1\",\"pts2\"]].agg(\"sum\").reset_index()\n",
    "    off_prior[\"OFF\"] = off_prior[\"pts1\"] / off_prior[\"poss1\"] \n",
    "    off_prior = off_prior[[\"tId1\",\"OFF\"]]\n",
    "    def_prior[\"DEF\"] = def_prior[\"pts2\"] / def_prior[\"poss1\"] \n",
    "    def_prior = def_prior[[\"tId1\",\"DEF\"]]\n",
    "    results_net = pd.merge(off_prior,def_prior,on=[\"tId1\"])\n",
    "    results_net[\"NET\"] = results_net[\"OFF\"] - results_net[\"DEF\"] \n",
    "    results_net.rename(columns={\"tId1\":\"tId\"},inplace=True)\n",
    "    results_net = results_net.astype(float).round(2)\n",
    "    results_net[\"tId\"] = results_net[\"tId\"].astype(int)\n",
    "    ortg_mean = data[\"pts1\"].sum()/data[\"poss1\"].sum()\n",
    "    drtg_mean = data[\"pts2\"].sum()/data[\"poss1\"].sum()    \n",
    "    results_adj[\"tId\"] = results_adj[\"tId\"].astype(int)\n",
    "    results_comb = pd.merge(results_net,results_adj,on=[\"tId\"])\n",
    "    results_comb[\"aOFF\"] = results_comb[\"aOFF\"] + intercept\n",
    "    results_comb[\"aDEF\"] = results_comb[\"aDEF\"] + intercept\n",
    "    results_comb[\"oSOS\"] = results_comb[\"aOFF\"] -results_comb[\"OFF\"]\n",
    "    results_comb[\"dSOS\"] = results_comb[\"DEF\"] -results_comb[\"aDEF\"]\n",
    "    results_comb[\"SOS\"] = results_comb[\"oSOS\"] + results_comb[\"dSOS\"]\n",
    "    results_comb.iloc[:,2:] = results_comb.iloc[:,2:].round(1)\n",
    "    # results = results_comb[[\"Team\",\"OFF\",\"oSOS\",\"aOFF\",\"DEF\",\"dSOS\",\"aDEF\",\"NET\",\"SOS\",\"aNET\"]]\n",
    "    results = results_comb[[\"Team\",\"OFF\",\"DEF\",\"NET\",\"aOFF\",\"aDEF\",\"aNET\"]]\n",
    "    results = results.sort_values(by=\"aNET\",ascending=0).reset_index(drop=True)\n",
    "    return results,ortg_mean,drtg_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maps_teams function\n",
    "1. Makes the matrix rows to be used in ridge regression\n",
    "2. The weights for each team = 1/2\n",
    "3. Equations per game are:  \n",
    "0.5*team1off_est + 0.5*team2def_est = team1offrating  \n",
    "0.5*team2off_est + 0.5*team1def_est = team2offrating  \n",
    "4. The reason for doing this is that for unadjusted values of a game, team1offrating = team2defrating.  \n",
    "So team1offrating = 0.5*team1offrating + 0.5*team2defrating. Therefore I use a similar structure for estimating adjusted ratings\n",
    "# convert_to_matrices\n",
    "1. Converts each row of data dataframe to x stints.\n",
    "2. Then maps those rows using `map_teams` function to get matrix X rows\n",
    "3. Gets Y rows\n",
    "# lambda_to_alpha\n",
    "Converts lambda value to alpha needed for ridge CV\n",
    "# calculate_netrtg\n",
    "1. Converts lambdas to alphas using `lambda_to_alpha` function\n",
    "2. Defines the ridge regression problem using `scikit-learn`'s `RidgeCV` algorithm\n",
    "3. `cv=5` is chosen i.e. kfold cross-validation splitting strategy using `k=5`\n",
    "4. `Intercept` is set as true. This value is to be added later to our estimation results to get Offensive and Defensive ratings.\n",
    "5. Gets coefficients and intercept\n",
    "6. Add intercept to intercept to get adjusted ratings. Use adjusted off and def ratings to calculate adjusted net rating.\n",
    "7. Create and return adjusted ratings dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_teams(row_in, teams,scale):\n",
    "    t1 = row_in[0]\n",
    "    t2 = row_in[1]\n",
    "\n",
    "    rowOut = np.zeros([len(teams) * 3])\n",
    "    rowOut[teams.index(t1)] = scale\n",
    "    rowOut[teams.index(t2) + len(teams)] = scale\n",
    "\n",
    "    return rowOut\n",
    "\n",
    "def convert_to_matricies(possessions, name, teams,scale = 1):\n",
    "    # extract only the columns we need\n",
    "    # Convert the columns of player ids into a numpy matrix\n",
    "    stints_x_base = possessions[['tId1', 'tId2']].to_numpy()\n",
    "    # Apply our mapping function to the numpy matrix\n",
    "    stint_X_rows = np.apply_along_axis(map_teams, 1, stints_x_base, teams,scale=scale)\n",
    "    # Convert the column of target values into a numpy matrix\n",
    "    stint_Y_rows = possessions[name].to_numpy()\n",
    "\n",
    "    # return matricies and possessions series\n",
    "    return stint_X_rows, stint_Y_rows\n",
    "# Convert lambda value to alpha needed for ridge CV\n",
    "def lambda_to_alpha(lambda_value, samples):\n",
    "    return (lambda_value * samples) / 2.0\n",
    "\n",
    "# Convert RidgeCV alpha back into a lambda value\n",
    "def alpha_to_lambda(alpha_value, samples):\n",
    "    return (alpha_value * 2.0) / samples\n",
    "\n",
    "def calculate_netrtg(train_x, train_y, lambdas, teams_list):\n",
    "    alphas = [lambda_to_alpha(l, train_x.shape[0]) for l in lambdas]\n",
    "    # create a 5 fold CV ridgeCV model. Our target data is not centered at 0, so we want to fit to an intercept.\n",
    "    clf = RidgeCV(alphas=alphas, cv=5, fit_intercept=True)\n",
    "\n",
    "    # fit our training data\n",
    "    model = clf.fit(train_x, train_y,)\n",
    "\n",
    "    # convert our list of players into a mx1 matrix\n",
    "    team_arr = np.transpose(np.array(teams_list).reshape(1, len(teams_list)))\n",
    "\n",
    "    # extract our coefficients into the offensive and defensive parts\n",
    "    coef_offensive_array = model.coef_[0:len(teams_list)][np.newaxis].T\n",
    "    coef_defensive_array = model.coef_[len(teams_list):2*len(teams_list)][np.newaxis].T\n",
    "    # concatenate the offensive and defensive values with the playey ids into a mx3 matrix\n",
    "    team_id_with_coef = np.concatenate([team_arr, coef_offensive_array, coef_defensive_array], axis=1)\n",
    "    # build a dataframe from our matrix\n",
    "    teams_coef = pd.DataFrame(team_id_with_coef)\n",
    "    intercept = model.intercept_\n",
    "    teams_coef.columns = [\"tId\",\"aOFF\",\"aDEF\"]\n",
    "    teams_coef[\"aNET\"] = teams_coef[\"aOFF\"] - teams_coef[\"aDEF\"]\n",
    "    teams_coef[\"aOFF\"] = teams_coef[\"aOFF\"] \n",
    "    teams_coef[\"aDEF\"] = teams_coef[\"aDEF\"] \n",
    "    teams_coef['Team']=teams_coef['tId'].map(teams_dict)\n",
    "    results = teams_coef[[\"tId\",\"Team\",\"aOFF\",\"aDEF\",\"aNET\"]]\n",
    "    results = results.sort_values(by=['aNET'],ascending=False).reset_index(drop=True)\n",
    "    return results,model,intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasons = np.arange(2010,2023,1).astype(str)\n",
    "# dfa = []\n",
    "# for season in seasons:\n",
    "#     df = get_ratings(season)\n",
    "#     dfa.append(df)\n",
    "# data = pd.concat(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_ratings(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = convert_to_matricies(data, \"ORtg1\", teams_list,scale=1/2)\n",
    "n = 1.5\n",
    "lambdas_net = [.01*n, .05*n, 0.1*n]\n",
    "results_adj,model,intercept = calculate_netrtg(train_x, train_y, lambdas_net, teams_list)\n",
    "results,ortg_mean,drtg_mean = process_results(data,results_adj,intercept)\n",
    "results\n",
    "# results.sort_values(by=\"aOFF\",ascending=0)\n",
    "# results.sort_values(by=\"aDEF\",ascending=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = \"NET\"\n",
    "# var1 = \"OFF\"\n",
    "# var1 = \"DEF\"\n",
    "var2 = \"a\" + var1\n",
    "slope, intercept, r, p, sterr = scipy.stats.linregress(x=results[var1], y=results[var2])\n",
    "r2 = r**2\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fig = sns.regplot(x = var1, y = var2, data = results, color =\"black\",scatter_kws = {\"color\":\"tab:blue\"} ,ax=ax)\n",
    "ax.text(0.05,0.9,r\"$r^2=$\"+f\"{round(r2,4)}\",transform = ax.transAxes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"R_HOME\"] = \"C:\\\\Program Files\\\\R\\\\R-4.3.2\\\\\"\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"OFF_R\"] = results[\"OFF\"].rank(ascending=False).astype(int)\n",
    "results[\"DEF_R\"] = results[\"DEF\"].rank(ascending=True).astype(int)\n",
    "results[\"NET_R\"] = results[\"NET\"].rank(ascending=False).astype(int)\n",
    "results[\"aOFF_R\"] = results[\"aOFF\"].rank(ascending=False).astype(int)\n",
    "results[\"aDEF_R\"] = results[\"aDEF\"].rank(ascending=True).astype(int)\n",
    "results[\"aNET_R\"] = results[\"aNET\"].rank(ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results \n",
    "library(tidyverse)\n",
    "library(gt)\n",
    "df <- results\n",
    "df %>% \n",
    "  gt()%>%\n",
    "  # cols_move(OFF_R,OFF) %>% cols_move(DEF_R,DEF) %>% cols_move(NET_R,NET) %>%\n",
    "  # cols_move(aOFF_R,aOFF) %>% cols_move(aDEF_R,aDEF) %>% cols_move(aNET_R,aNET) %>%\n",
    "  tab_header(\n",
    "    title = md(\"**NBA Adjusted Net Rating Leaders 2023-24**\"),\n",
    "    subtitle = md(\"The Offensive, Defensive and Net Ratings are adjusted for Strength of Schedule\" )\n",
    "    ) %>%\n",
    "    data_color(columns = c(OFF,aOFF,NET,aNET), palette = c(\"red\", \"green\")) %>%\n",
    "    data_color(columns = c(DEF,aDEF), palette = c(\"green\",\"red\")) %>%\n",
    "    cols_align(align = \"center\",columns = c(OFF,DEF,NET,aOFF,aDEF,aNET))  %>%\n",
    "    cols_label(\n",
    "      OFF_R = \"#\",DEF_R = \"#\",NET_R = \"#\",aOFF_R = \"#\",aDEF_R = \"#\",aNET_R = \"#\"\n",
    "    ) %>%\n",
    "    tab_options(\n",
    "        table.background.color = \"floralwhite\",\n",
    "        column_labels.font.size = 12,\n",
    "        column_labels.font.weight = 'bold',\n",
    "        row_group.font.weight = 'bold',\n",
    "        row_group.background.color = \"#E5E1D8\",\n",
    "        table.font.size = 10,\n",
    "        heading.title.font.size = 20,\n",
    "        heading.subtitle.font.size = 12.5,\n",
    "        table.font.names = \"Consolas\", \n",
    "        data_row.padding = px(2)\n",
    "    ) %>% \n",
    "    tab_spanner(\n",
    "      label = \"Unadjusted\",\n",
    "      columns = c(OFF, OFF_R, DEF, DEF_R, NET, NET_R)\n",
    "    ) %>%\n",
    "    tab_spanner(\n",
    "      label = \"Adjusted\",\n",
    "      columns = c(aOFF, aOFF_R, aDEF, aDEF_R, aNET, aNET_R)\n",
    "    ) %>%\n",
    "    tab_source_note(\n",
    "    source_note = \"SOS adjustments done using Ridge Regression Method to estimate Off and Def Ratings\" ) %>% \n",
    "    tab_source_note(\n",
    "    source_note = \"@SravanNBA | Source: nba.com/stats\" ) %>% gtsave(\"../figs/team_leaders/Teams_aNET.png\",zoom=5) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ub9Z_EQq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
