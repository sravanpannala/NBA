{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Injury Data from https://www.prosportstransactions.com/\n",
    "### Code adopted from:\n",
    "- https://github.com/gboogy/nba-injury-data-scraper\n",
    "- https://github.com/elap733/NBA-Injuries-Analysis/blob/master/src/d01_scrapes/scrape_missedgames.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from thefuzz import fuzz\n",
    "\n",
    "pd.options.mode.chained_assignment =  None\n",
    "# Pretending to be a browser\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../data/NBA.json\")\n",
    "data = json.load(f)\n",
    "data = data[\"players\"]\n",
    "pID_dict = {v: int(k) for k, v in data.items()}\n",
    "player_dict = {int(k): v for k, v in data.items()}\n",
    "# pID = pID_dict.get(player, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15\n"
     ]
    }
   ],
   "source": [
    "# Start Date\n",
    "try:\n",
    "    df0 = pd.read_parquet('../fdata/NBA_prosptran_injuries_2023.parquet')\n",
    "    start_date = (df0[\"Date\"].iloc[-1] + datetime.timedelta(days=-1)).strftime(\"%Y-%m-%d\")\n",
    "except:\n",
    "    start_date = \"2023-06-01\"\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL to scrape from \n",
    "url = f\"https://www.prosportstransactions.com/basketball/Search/SearchResults.php?Player=&Team=&BeginDate={start_date}&EndDate=&ILChkBx=yes&InjuriesChkBx=yes&PersonalChkBx=yes&Submit=Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#-------------Scrape web page--------------------------------------\n",
    "\n",
    "#Get URL HTML\n",
    "response = requests.get(url)\n",
    "print(response) # Response [200] means it went through\n",
    "\n",
    "#Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#-------------Scrape data from the first web page----------------\n",
    "#Read in html as pandas data frame\n",
    "df_first_page = pd.read_html(url,storage_options=header)\n",
    "    \n",
    "#Select table of interest (the first table)\n",
    "df_first_page = df_first_page[0]\n",
    "\n",
    "#Drop first row (column names)\n",
    "df_first_page.drop([0], inplace = True)\n",
    "   \n",
    "#Remove bullet in front of player names\n",
    "df_first_page[2]=df_first_page[2].str[2:] # \"Acquired\" column\n",
    "df_first_page[3]=df_first_page[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "#Modify column titles\n",
    "df_first_page.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "\n",
    "dfa = []\n",
    "#data frame list to hold data for concating later\n",
    "dfa.append(df_first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "#------------Scrape data from other pages linked at the bottom of the first page------------\n",
    "# Loop over links (skipping the first 4 (not data) and last 4 (\"Next\" and other webpage links))\n",
    "for i in tqdm(range(4,len(soup.findAll('a'))-4)): #'a' tags are for links\n",
    "   \n",
    "    #find all links on webpage and select the i-th link\n",
    "    one_a_tag = soup.findAll('a')[i]\n",
    "    link = one_a_tag['href']\n",
    "    \n",
    "    #Add in the rest of the url\n",
    "    download_url = 'https://www.prosportstransactions.com/basketball/Search/'+ link\n",
    "    # print(download_url)\n",
    "    \n",
    "    #Read html as pandas data frame\n",
    "    dfs = pd.read_html(download_url, storage_options=header)\n",
    "    \n",
    "    #Select table of interest (the first table)\n",
    "    df = dfs[0]\n",
    "    \n",
    "    #Drop first row (column names)\n",
    "    df.drop([0], inplace = True)\n",
    "   \n",
    "    #Remove bullet in front of names\n",
    "    df[2]=df[2].str[2:] # \"Acquired\" column\n",
    "    df[3]=df[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "    #Modify column titles\n",
    "    df.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "    #Add a pause to keep web server happy\n",
    "    time.sleep(1)\n",
    "    dfa.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_pId(player):\n",
    "    frat = [[v,fuzz.ratio(player,k)] for k, v in pID_dict.items()]\n",
    "    frar  = np.array(frat).T\n",
    "    pId = frar[:,frar.argmax(axis=1)[1]][0]\n",
    "    return pId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.concat(dfa)\n",
    "df = df1.copy()\n",
    "acq = df['Acquired']\n",
    "rel = df['Relinquished']\n",
    "df['Acquired'] = np.where(\n",
    "    acq.str.contains('/'), acq.str.split('/ ').str[1], acq)\n",
    "df['Relinquished'] = np.where(\n",
    "    rel.str.contains('/'), rel.str.split('/ ').str[1], rel)\n",
    "\n",
    "# Remove instances where value is like \"(some text)\"\n",
    "df['Acquired'] = df.Acquired.str.replace(\n",
    "    r\"[\\(\\[].*?[\\)\\]]\", \"\")\n",
    "df['Relinquished'] = df.Relinquished.str.replace(\n",
    "    r\"[\\(\\[].*?[\\)\\]]\", \"\")\n",
    "df[\"Act\"] = ~df[\"Acquired\"].isna()\n",
    "df[\"DAct\"] = ~df[\"Relinquished\"].isna()\n",
    "df[\"Player\"] =  (df[\"Acquired\"]*~df[\"Acquired\"].isna()).fillna(\"\") +\\\n",
    "                (df[\"Relinquished\"]*~df[\"Relinquished\"].isna()).fillna(\"\")\n",
    "df = df[[\"Date\",\"Team\",\"Player\",\"Act\",\"DAct\",\"Notes\"]]\n",
    "df = df[df[\"Player\"].str.istitle()].reset_index(drop=True)\n",
    "df[\"playerID\"] = df[\"Player\"].map(pID_dict)\n",
    "df1 = df.copy()\n",
    "df1[\"playerID\"][df[\"playerID\"].isna()] = df[\"Player\"][df[\"playerID\"].isna()].apply(lambda x: get_missing_pId(x))\n",
    "df1[\"playerID\"] = df1[\"playerID\"].astype(int)\n",
    "df1[\"Date\"] = pd.to_datetime(df1[\"Date\"], format=\"%Y-%m-%d\")\n",
    "df1.insert(2,\"playerID\",df1.pop(\"playerID\"))\n",
    "df2 = pd.concat([df0,df1]).reset_index(drop=True)\n",
    "df3 =df2[~df2.duplicated(keep='last')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('../fdata/NBA_prosptran_injuries_2023.csv', index=False)\n",
    "df3.to_parquet('../fdata/NBA_prosptran_injuries_2023.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df3.query(\"Player == 'Tyler Herro'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>playerID</th>\n",
       "      <th>Player</th>\n",
       "      <th>Act</th>\n",
       "      <th>DAct</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>Heat</td>\n",
       "      <td>1629639</td>\n",
       "      <td>Tyler Herro</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>activated from IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>Heat</td>\n",
       "      <td>1629639</td>\n",
       "      <td>Tyler Herro</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>sprained right ankle (DTD)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Team  playerID       Player    Act   DAct  \\\n",
       "0 2023-06-12  Heat   1629639  Tyler Herro   True  False   \n",
       "1 2023-11-09  Heat   1629639  Tyler Herro  False   True   \n",
       "\n",
       "                        Notes  \n",
       "0           activated from IL  \n",
       "1  sprained right ankle (DTD)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did Herro Miss the game on 1st November?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_date = pd.to_datetime(datetime.date(2023,11,1))\n",
    "dfp[\"Comp\"] = dfp[\"Date\"] <= game_date\n",
    "idxi = dfp[dfp[\"Comp\"]].index\n",
    "if len(idxi) > 0:\n",
    "    idx = idxi[-1]\n",
    "    missed_game = dfp[\"DAct\"].loc[idx]\n",
    "else:\n",
    "    missed_game = False\n",
    "missed_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ub9Z_EQq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
