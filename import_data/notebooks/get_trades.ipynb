{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from thefuzz import fuzz, process\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed, Retrying\n",
    "\n",
    "pd.options.mode.chained_assignment =  None\n",
    "\n",
    "data_DIR = \"../../data/injuries/\"\n",
    "export_DIR = \"../../../repos/csv/\"\n",
    "# Pretending to be a browser\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "with open(\"../../data/NBA.json\") as f:\n",
    "    data = json.load(f)\n",
    "pID_dict = {v: int(k) for k, v in data.items()}\n",
    "player_dict = {int(k): v for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Date\n",
    "start_date = \"2000-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame()\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including these following conditions:\n",
    "- Movement to/from injured/inactive list (IL)\n",
    "- Missed games due to injury\n",
    "- Missed games due to personal reasons\n",
    "- Missed games due to suspensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL to scrape from \n",
    "url = f\"https://www.prosportstransactions.com/basketball/Search/SearchResults.php?Player=&Team=&BeginDate={start_date}&EndDate=&PlayerMovementChkBx=yes&Submit=Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------Scrape web page--------------------------------------\n",
    "\n",
    "#Get URL HTML\n",
    "response = requests.get(url)\n",
    "print(response) # Response [200] means it went through\n",
    "\n",
    "#Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#-------------Scrape data from the first web page----------------\n",
    "#Read in html as pandas data frame\n",
    "df_first_page = pd.read_html(url,storage_options=header)\n",
    "    \n",
    "#Select table of interest (the first table)\n",
    "df_first_page = df_first_page[0]\n",
    "\n",
    "#Drop first row (column names)\n",
    "df_first_page.drop([0], inplace = True)\n",
    "   \n",
    "#Remove bullet in front of player names\n",
    "df_first_page[2]=df_first_page[2].str[2:] # \"Acquired\" column\n",
    "df_first_page[3]=df_first_page[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "#Modify column titles\n",
    "df_first_page.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "\n",
    "dfa = []\n",
    "#data frame list to hold data for concating later\n",
    "dfa.append(df_first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Scrape data from other pages linked at the bottom of the first page------------\n",
    "# Loop over links (skipping the first 4 (not data) and last 4 (\"Next\" and other webpage links))\n",
    "for i in tqdm(range(4,len(soup.findAll('a'))-4)): #'a' tags are for links\n",
    "   \n",
    "    #find all links on webpage and select the i-th link\n",
    "    one_a_tag = soup.findAll('a')[i]\n",
    "    link = one_a_tag['href']\n",
    "    \n",
    "    #Add in the rest of the url\n",
    "    download_url = 'https://www.prosportstransactions.com/basketball/Search/'+ link\n",
    "    # print(download_url)\n",
    "    \n",
    "    #Read html as pandas data frame\n",
    "    dfs = pd.read_html(download_url, storage_options=header)\n",
    "    \n",
    "    #Select table of interest (the first table)\n",
    "    df = dfs[0]\n",
    "    \n",
    "    #Drop first row (column names)\n",
    "    df.drop([0], inplace = True)\n",
    "   \n",
    "    #Remove bullet in front of names\n",
    "    df[2]=df[2].str[2:] # \"Acquired\" column\n",
    "    df[3]=df[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "    #Modify column titles\n",
    "    df.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "    #Add a pause to keep web server happy\n",
    "    time.sleep(0.2)\n",
    "    dfa.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.concat(dfa)\n",
    "df = df11.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"Notes\"].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(data_DIR + \"all_trades.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_DIR + \"all_trades.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Clippets\",\"Clippers\")\n",
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Grizzles\",\"Grizzlies\")\n",
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Lakerse\",\"Lakers\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Clippets\",\"Clippers\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Grizzles\",\"Grizzlies\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Lakerse\",\"Lakers\")\n",
    "df = df[~(df[\"Notes\"].str.contains(\"void\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"Notes\"].str.contains(\"trade\")]\n",
    "df1 = df1[df1[\"Date\"] >= \"2010-07-01\"].reset_index(drop=True)\n",
    "df1[\"tradetype\"] = df1[\"Notes\"].str.split(' ').str[0]\n",
    "df1 = df1[~(df1[\"tradetype\"] == \"earlier\")].reset_index(drop=True)\n",
    "df1 = df1.rename(columns={\"Team\":\"Team1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = df1[df1[\"tradetype\"] == \"trade\"].reset_index(drop=True)\n",
    "df1_1[\"Team2\"] = df1_1[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_1.insert(2,\"Team2\",df1_1.pop(\"Team2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2 = df1[df1[\"tradetype\"] == \"3-team\"].reset_index(drop=True)\n",
    "df1_2[\"Team2\"] = df1_2[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_2[\"Team3\"] = df1_2[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_2.insert(2,\"Team2\",df1_2.pop(\"Team2\"))\n",
    "df1_2.insert(3,\"Team3\",df1_2.pop(\"Team3\"))\n",
    "df1_2[\"Team2\"] = df1_2[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_21 = df1_2.drop(columns= \"Team3\")\n",
    "df1_22 = df1_2.drop(columns= \"Team2\")\n",
    "df1_22 = df1_22.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_2 = pd.concat([df1_21,df1_22]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1[\"tradetype\"] == \"3-team\") & (df1[\"Date\"] == \"2019-02-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2[df1_2[\"Date\"] == \"2019-02-07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_3 = df1[df1[\"tradetype\"] == \"4-team\"].reset_index(drop=True)\n",
    "df1_3[\"Team2\"] = df1_3[\"Notes\"].str.split(' ').str[-3]\n",
    "df1_3[\"Team3\"] = df1_3[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_3[\"Team4\"] = df1_3[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_3.insert(2,\"Team2\",df1_3.pop(\"Team2\"))\n",
    "df1_3.insert(3,\"Team3\",df1_3.pop(\"Team3\"))\n",
    "df1_3.insert(4,\"Team4\",df1_3.pop(\"Team4\"))\n",
    "df1_3[\"Team2\"] = df1_3[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_3[\"Team3\"] = df1_3[\"Team3\"].str.replace(\",\",\"\")\n",
    "df1_31 = df1_3.drop(columns= [\"Team3\",\"Team4\"])\n",
    "df1_32 = df1_3.drop(columns= [\"Team2\",\"Team4\"])\n",
    "df1_33 = df1_3.drop(columns= [\"Team2\",\"Team3\"])\n",
    "df1_32 = df1_32.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_33 = df1_33.rename(columns={\"Team4\":\"Team2\"})\n",
    "df1_3 = pd.concat([df1_31,df1_32,df1_33]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)\n",
    "\n",
    "df1_4 = df1[df1[\"tradetype\"] == \"5-team\"].reset_index(drop=True)\n",
    "df1_4[\"Team2\"] = df1_4[\"Notes\"].str.split(' ').str[-4]\n",
    "df1_4[\"Team3\"] = df1_4[\"Notes\"].str.split(' ').str[-3]\n",
    "df1_4[\"Team4\"] = df1_4[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_4[\"Team5\"] = df1_4[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_4.insert(2,\"Team2\",df1_4.pop(\"Team2\"))\n",
    "df1_4.insert(3,\"Team3\",df1_4.pop(\"Team3\"))\n",
    "df1_4.insert(4,\"Team4\",df1_4.pop(\"Team4\"))\n",
    "df1_4.insert(5,\"Team5\",df1_4.pop(\"Team5\"))\n",
    "df1_4[\"Team2\"] = df1_4[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_4[\"Team3\"] = df1_4[\"Team3\"].str.replace(\",\",\"\")\n",
    "df1_4[\"Team4\"] = df1_4[\"Team4\"].str.replace(\",\",\"\")\n",
    "df1_41 = df1_4.drop(columns= [\"Team3\",\"Team4\",\"Team5\"])\n",
    "df1_42 = df1_4.drop(columns= [\"Team2\",\"Team4\",\"Team5\"])\n",
    "df1_43 = df1_4.drop(columns= [\"Team2\",\"Team3\",\"Team5\"])\n",
    "df1_44 = df1_4.drop(columns= [\"Team2\",\"Team3\",\"Team4\"])\n",
    "df1_42 = df1_42.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_43 = df1_43.rename(columns={\"Team4\":\"Team2\"})\n",
    "df1_44 = df1_44.rename(columns={\"Team5\":\"Team2\"})\n",
    "df1_4 = pd.concat([df1_41,df1_42,df1_43,df1_44]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)\n",
    "\n",
    "df2 = pd.concat([df1_1,df1_2,df1_3,df1_4]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hired as general manager\"\n",
    "\"hired as president of basketball operations\"\n",
    "\"hired as president & general manager\"\n",
    "\"hired as vice president of basketball operations\"\n",
    "\"hired as VP of basketball operations\"\n",
    "\n",
    "\"promoted to general manager\"\n",
    "\"promoted to president of basketball operations\"\n",
    "\"promoted to president & general manager\"\n",
    "\"promoted to vice president of basketball operations\"\n",
    "\"promoted to VP of basketball operations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_1 = df[df[\"Notes\"].str.contains(\"hired as general manager\")]\n",
    "df3_2 = df[df[\"Notes\"].str.contains(\"hired as president of basketball operations\")]\n",
    "df3_3 = df[df[\"Notes\"].str.contains(\"hired as president & general manager\")]\n",
    "df3_4 = df[df[\"Notes\"].str.contains(\"hired as vice president of basketball operations\")]\n",
    "df3_5 = df[df[\"Notes\"].str.contains(\"hired as VP of basketball operations\")]\n",
    "df3_6 = df[df[\"Notes\"].str.contains(\"hired as executive vice president of basketball operations\")]\n",
    "df3_7 = df[df[\"Notes\"].str.contains(\"promoted to general manager\")]\n",
    "df3_8 = df[df[\"Notes\"].str.contains(\"promoted to president of basketball operations\")]\n",
    "df3_9 = df[df[\"Notes\"].str.contains(\"promoted to president & general manager\")]\n",
    "df3_10 = df[df[\"Notes\"].str.contains(\"promoted to vice president of basketball operations\")]\n",
    "df3_11 = df[df[\"Notes\"].str.contains(\"promoted to VP of basketball operations\")]\n",
    "df3_12 = df[df[\"Notes\"].str.contains(\"promoted to executive vice president of basketball operations\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df3_1,df3_2,df3_3,df3_4,df3_5,df3_6,df3_7,df3_8,df3_9,df3_10,df3_11,df3_12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.sort_values([\"Team\",\"Date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.to_csv(\"executives.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_1 = df2.query(\"Date < '2013-07-01'\")\n",
    "df4_2 = df2.query(\"Date >= '2013-07-01'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_1[\"Team1\"] = df4_1[\"Team1\"].str.replace(\"Hornets\",\"Pelicans\")\n",
    "df4_1[\"Team2\"] = df4_1[\"Team2\"].str.replace(\"Hornets\",\"Pelicans\")\n",
    "df4_1[\"Team1\"] = df4_1[\"Team1\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_1[\"Team2\"] = df4_1[\"Team2\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_2[\"Team1\"] = df4_2[\"Team1\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_2[\"Team2\"] = df4_2[\"Team2\"].str.replace(\"Bobcats\",\"Hornets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df4_1,df4_2]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4[\"Team1\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3  = pd.read_csv(\"executives.csv\")\n",
    "df3[\"Date\"] = pd.to_datetime(df3[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns=[\"Relinquished\",\"Notes\"])\n",
    "df3 = df3.rename(columns={\"Acquired\":\"Executive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = dt.datetime(year=2024, month=6,day=30)\n",
    "end_date = datetime(end_date.year, end_date.month, end_date.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3g = df3.groupby(\"Team\")\n",
    "keys = list(df3g.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfia = []\n",
    "for key in keys:\n",
    "    dfi = df3g.get_group(key)\n",
    "    dfi = pd.concat([dfi.head(1),dfi])\n",
    "    dfi[\"Date1\"] = dfi[\"Date\"].shift(periods=-1)\n",
    "    dfi[\"Date1\"].iloc[-1] = end_date\n",
    "    dfi['Dater'] = dfi.apply(lambda row: pd.date_range(row[\"Date\"], row['Date1'], freq='D'), axis=1)\n",
    "    dfj = dfi.explode('Dater').reset_index(drop=True) \\\n",
    "            .drop(columns=['Date', 'Date1']) \\\n",
    "            .rename(columns={'Dater': 'Date'}) \n",
    "    dfj.insert(0,\"Date\",dfj.pop(\"Date\"))\n",
    "    dfia.append(dfj)\n",
    "dfe = pd.concat(dfia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"Date\"] = pd.to_datetime(df4[\"Date\"], format=\"%Y-%m-%d\")\n",
    "df5_1 = pd.merge(df4,dfe,left_on=[\"Date\",\"Team1\"],right_on=[\"Date\",\"Team\"])\n",
    "df5_1 = df5_1.rename(columns={\"Executive\":\"Executive1\"})\n",
    "df5_1 = df5_1.drop(columns=\"Team\")\n",
    "df5_2 = pd.merge(df5_1,dfe,left_on=[\"Date\",\"Team2\"],right_on=[\"Date\",\"Team\"])\n",
    "df5 = df5_2.rename(columns={\"Executive\":\"Executive2\"})\n",
    "df5 = df5.drop(columns=\"Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"../../data/misc/\" + \"Trades_w_Executives.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ub9Z_EQq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
