{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from thefuzz import fuzz, process\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed, Retrying\n",
    "\n",
    "pd.options.mode.chained_assignment =  None\n",
    "\n",
    "data_DIR = \"../../data/injuries/\"\n",
    "export_DIR = \"../../../repos/csv/\"\n",
    "# Pretending to be a browser\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "with open(\"../../data/NBA.json\") as f:\n",
    "    data = json.load(f)\n",
    "pID_dict = {v: int(k) for k, v in data.items()}\n",
    "player_dict = {int(k): v for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Date\n",
    "start_date = \"2000-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame()\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL to scrape from \n",
    "url = f\"https://www.prosportstransactions.com/basketball/Search/SearchResults.php?Player=&Team=&BeginDate={start_date}&EndDate=&PlayerMovementChkBx=yes&Submit=Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------Scrape web page--------------------------------------\n",
    "\n",
    "#Get URL HTML\n",
    "response = requests.get(url)\n",
    "print(response) # Response [200] means it went through\n",
    "\n",
    "#Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#-------------Scrape data from the first web page----------------\n",
    "#Read in html as pandas data frame\n",
    "df_first_page = pd.read_html(url,storage_options=header)\n",
    "    \n",
    "#Select table of interest (the first table)\n",
    "df_first_page = df_first_page[0]\n",
    "\n",
    "#Drop first row (column names)\n",
    "df_first_page.drop([0], inplace = True)\n",
    "   \n",
    "#Remove bullet in front of player names\n",
    "df_first_page[2]=df_first_page[2].str[2:] # \"Acquired\" column\n",
    "df_first_page[3]=df_first_page[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "#Modify column titles\n",
    "df_first_page.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "\n",
    "dfa = []\n",
    "#data frame list to hold data for concating later\n",
    "dfa.append(df_first_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------Scrape data from other pages linked at the bottom of the first page------------\n",
    "# Loop over links (skipping the first 4 (not data) and last 4 (\"Next\" and other webpage links))\n",
    "for i in tqdm(range(4,len(soup.findAll('a'))-4)): #'a' tags are for links\n",
    "   \n",
    "    #find all links on webpage and select the i-th link\n",
    "    one_a_tag = soup.findAll('a')[i]\n",
    "    link = one_a_tag['href']\n",
    "    \n",
    "    #Add in the rest of the url\n",
    "    download_url = 'https://www.prosportstransactions.com/basketball/Search/'+ link\n",
    "    # print(download_url)\n",
    "    \n",
    "    #Read html as pandas data frame\n",
    "    dfs = pd.read_html(download_url, storage_options=header)\n",
    "    \n",
    "    #Select table of interest (the first table)\n",
    "    df = dfs[0]\n",
    "    \n",
    "    #Drop first row (column names)\n",
    "    df.drop([0], inplace = True)\n",
    "   \n",
    "    #Remove bullet in front of names\n",
    "    df[2]=df[2].str[2:] # \"Acquired\" column\n",
    "    df[3]=df[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "    #Modify column titles\n",
    "    df.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "    #Add a pause to keep web server happy\n",
    "    time.sleep(0.2)\n",
    "    dfa.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.concat(dfa)\n",
    "df = df11.copy()\n",
    "df = df[~df[\"Notes\"].isna()].reset_index(drop=True)\n",
    "df.to_parquet(data_DIR + \"all_trades.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(data_DIR + \"all_trades.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Clippets\",\"Clippers\")\n",
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Grizzles\",\"Grizzlies\")\n",
    "df[\"Team\"] = df[\"Team\"].str.replace(\"Lakerse\",\"Lakers\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Clippets\",\"Clippers\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Grizzles\",\"Grizzlies\")\n",
    "df[\"Notes\"] = df[\"Notes\"].str.replace(\"Lakerse\",\"Lakers\")\n",
    "df = df[~(df[\"Notes\"].str.contains(\"void\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"Notes\"].str.contains(\"trade\")]\n",
    "df1 = df1[df1[\"Date\"] >= \"2010-07-01\"].reset_index(drop=True)\n",
    "df1[\"tradetype\"] = df1[\"Notes\"].str.split(' ').str[0]\n",
    "df1 = df1[~(df1[\"tradetype\"] == \"earlier\")].reset_index(drop=True)\n",
    "df1 = df1.rename(columns={\"Team\":\"Team1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = df1[df1[\"tradetype\"] == \"trade\"].reset_index(drop=True)\n",
    "df1_1[\"Team2\"] = df1_1[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_1.insert(2,\"Team2\",df1_1.pop(\"Team2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2 = df1[df1[\"tradetype\"] == \"3-team\"].reset_index(drop=True)\n",
    "df1_2[\"Team2\"] = df1_2[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_2[\"Team3\"] = df1_2[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_2.insert(2,\"Team2\",df1_2.pop(\"Team2\"))\n",
    "df1_2.insert(3,\"Team3\",df1_2.pop(\"Team3\"))\n",
    "df1_2[\"Team2\"] = df1_2[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_21 = df1_2.drop(columns= \"Team3\")\n",
    "df1_22 = df1_2.drop(columns= \"Team2\")\n",
    "df1_22 = df1_22.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_2 = pd.concat([df1_21,df1_22]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[(df1[\"tradetype\"] == \"3-team\") & (df1[\"Date\"] == \"2019-02-07\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_2[df1_2[\"Date\"] == \"2019-02-07\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_3 = df1[df1[\"tradetype\"] == \"4-team\"].reset_index(drop=True)\n",
    "df1_3[\"Team2\"] = df1_3[\"Notes\"].str.split(' ').str[-3]\n",
    "df1_3[\"Team3\"] = df1_3[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_3[\"Team4\"] = df1_3[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_3.insert(2,\"Team2\",df1_3.pop(\"Team2\"))\n",
    "df1_3.insert(3,\"Team3\",df1_3.pop(\"Team3\"))\n",
    "df1_3.insert(4,\"Team4\",df1_3.pop(\"Team4\"))\n",
    "df1_3[\"Team2\"] = df1_3[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_3[\"Team3\"] = df1_3[\"Team3\"].str.replace(\",\",\"\")\n",
    "df1_31 = df1_3.drop(columns= [\"Team3\",\"Team4\"])\n",
    "df1_32 = df1_3.drop(columns= [\"Team2\",\"Team4\"])\n",
    "df1_33 = df1_3.drop(columns= [\"Team2\",\"Team3\"])\n",
    "df1_32 = df1_32.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_33 = df1_33.rename(columns={\"Team4\":\"Team2\"})\n",
    "df1_3 = pd.concat([df1_31,df1_32,df1_33]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)\n",
    "\n",
    "df1_4 = df1[df1[\"tradetype\"] == \"5-team\"].reset_index(drop=True)\n",
    "df1_4[\"Team2\"] = df1_4[\"Notes\"].str.split(' ').str[-4]\n",
    "df1_4[\"Team3\"] = df1_4[\"Notes\"].str.split(' ').str[-3]\n",
    "df1_4[\"Team4\"] = df1_4[\"Notes\"].str.split(' ').str[-2]\n",
    "df1_4[\"Team5\"] = df1_4[\"Notes\"].str.split(' ').str[-1]\n",
    "df1_4.insert(2,\"Team2\",df1_4.pop(\"Team2\"))\n",
    "df1_4.insert(3,\"Team3\",df1_4.pop(\"Team3\"))\n",
    "df1_4.insert(4,\"Team4\",df1_4.pop(\"Team4\"))\n",
    "df1_4.insert(5,\"Team5\",df1_4.pop(\"Team5\"))\n",
    "df1_4[\"Team2\"] = df1_4[\"Team2\"].str.replace(\",\",\"\")\n",
    "df1_4[\"Team3\"] = df1_4[\"Team3\"].str.replace(\",\",\"\")\n",
    "df1_4[\"Team4\"] = df1_4[\"Team4\"].str.replace(\",\",\"\")\n",
    "df1_41 = df1_4.drop(columns= [\"Team3\",\"Team4\",\"Team5\"])\n",
    "df1_42 = df1_4.drop(columns= [\"Team2\",\"Team4\",\"Team5\"])\n",
    "df1_43 = df1_4.drop(columns= [\"Team2\",\"Team3\",\"Team5\"])\n",
    "df1_44 = df1_4.drop(columns= [\"Team2\",\"Team3\",\"Team4\"])\n",
    "df1_42 = df1_42.rename(columns={\"Team3\":\"Team2\"})\n",
    "df1_43 = df1_43.rename(columns={\"Team4\":\"Team2\"})\n",
    "df1_44 = df1_44.rename(columns={\"Team5\":\"Team2\"})\n",
    "df1_4 = pd.concat([df1_41,df1_42,df1_43,df1_44]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)\n",
    "\n",
    "df2 = pd.concat([df1_1,df1_2,df1_3,df1_4]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"hired as general manager\"\n",
    "\"hired as president of basketball operations\"\n",
    "\"hired as president & general manager\"\n",
    "\"hired as vice president of basketball operations\"\n",
    "\"hired as VP of basketball operations\"\n",
    "\n",
    "\"promoted to general manager\"\n",
    "\"promoted to president of basketball operations\"\n",
    "\"promoted to president & general manager\"\n",
    "\"promoted to vice president of basketball operations\"\n",
    "\"promoted to VP of basketball operations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_1 = df[df[\"Notes\"].str.contains(\"hired as general manager\")]\n",
    "df3_2 = df[df[\"Notes\"].str.contains(\"hired as president of basketball operations\")]\n",
    "df3_3 = df[df[\"Notes\"].str.contains(\"hired as president & general manager\")]\n",
    "df3_4 = df[df[\"Notes\"].str.contains(\"hired as vice president of basketball operations\")]\n",
    "df3_5 = df[df[\"Notes\"].str.contains(\"hired as VP of basketball operations\")]\n",
    "df3_6 = df[df[\"Notes\"].str.contains(\"hired as executive vice president of basketball operations\")]\n",
    "df3_7 = df[df[\"Notes\"].str.contains(\"promoted to general manager\")]\n",
    "df3_8 = df[df[\"Notes\"].str.contains(\"promoted to president of basketball operations\")]\n",
    "df3_9 = df[df[\"Notes\"].str.contains(\"promoted to president & general manager\")]\n",
    "df3_10 = df[df[\"Notes\"].str.contains(\"promoted to vice president of basketball operations\")]\n",
    "df3_11 = df[df[\"Notes\"].str.contains(\"promoted to VP of basketball operations\")]\n",
    "df3_12 = df[df[\"Notes\"].str.contains(\"promoted to executive vice president of basketball operations\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df3_1,df3_2,df3_3,df3_4,df3_5,df3_6,df3_7,df3_8,df3_9,df3_10,df3_11,df3_12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.sort_values([\"Team\",\"Date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.to_csv(\"executives.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_1 = df2.query(\"Date < '2013-07-01'\")\n",
    "df4_2 = df2.query(\"Date >= '2013-07-01'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_1[\"Team1\"] = df4_1[\"Team1\"].str.replace(\"Hornets\",\"Pelicans\")\n",
    "df4_1[\"Team2\"] = df4_1[\"Team2\"].str.replace(\"Hornets\",\"Pelicans\")\n",
    "df4_1[\"Team1\"] = df4_1[\"Team1\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_1[\"Team2\"] = df4_1[\"Team2\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_2[\"Team1\"] = df4_2[\"Team1\"].str.replace(\"Bobcats\",\"Hornets\")\n",
    "df4_2[\"Team2\"] = df4_2[\"Team2\"].str.replace(\"Bobcats\",\"Hornets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df4_1,df4_2]).sort_values([\"Date\",\"Team1\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4[\"Team1\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3  = pd.read_csv(\"executives.csv\")\n",
    "df3[\"Date\"] = pd.to_datetime(df3[\"Date\"], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(columns=[\"Relinquished\",\"Notes\"])\n",
    "df3 = df3.rename(columns={\"Acquired\":\"Executive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = dt.datetime(year=2024, month=6,day=30)\n",
    "end_date = datetime(end_date.year, end_date.month, end_date.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3g = df3.groupby(\"Team\")\n",
    "keys = list(df3g.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfia = []\n",
    "for key in keys:\n",
    "    dfi = df3g.get_group(key)\n",
    "    dfi = pd.concat([dfi.head(1),dfi])\n",
    "    dfi[\"Date1\"] = dfi[\"Date\"].shift(periods=-1)\n",
    "    dfi[\"Date1\"].iloc[-1] = end_date\n",
    "    dfi['Dater'] = dfi.apply(lambda row: pd.date_range(row[\"Date\"], row['Date1'], freq='D'), axis=1)\n",
    "    dfj = dfi.explode('Dater').reset_index(drop=True) \\\n",
    "            .drop(columns=['Date', 'Date1']) \\\n",
    "            .rename(columns={'Dater': 'Date'}) \n",
    "    dfj.insert(0,\"Date\",dfj.pop(\"Date\"))\n",
    "    dfia.append(dfj)\n",
    "dfe = pd.concat(dfia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"Date\"] = pd.to_datetime(df4[\"Date\"], format=\"%Y-%m-%d\")\n",
    "df5_1 = pd.merge(df4,dfe,left_on=[\"Date\",\"Team1\"],right_on=[\"Date\",\"Team\"])\n",
    "df5_1 = df5_1.rename(columns={\"Executive\":\"Executive1\"})\n",
    "df5_1 = df5_1.drop(columns=\"Team\")\n",
    "df5_2 = pd.merge(df5_1,dfe,left_on=[\"Date\",\"Team2\"],right_on=[\"Date\",\"Team\"])\n",
    "df5 = df5_2.rename(columns={\"Executive\":\"Executive2\"})\n",
    "df5 = df5.drop(columns=\"Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"../../data/misc/\" + \"Trades_w_Executives.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_pId(player, player_dict):\n",
    "    pId = process.extract(player, player_dict, scorer=fuzz.partial_ratio, limit=1)[0][2]\n",
    "    return pId\n",
    "def get_missing_tId(team, team_dict):\n",
    "    tId = process.extract(team, team_dict, scorer=fuzz.partial_ratio, limit=1)[0][2]\n",
    "    return tId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_data = pd.read_csv(\"../../data/NBA_teams_database.csv\")\n",
    "team_list = team_data[\"TeamID\"].tolist()\n",
    "team_dict1 = team_data.to_dict(orient=\"records\")\n",
    "team_dict = {team[\"TeamID\"]: team[\"Team\"] for team in team_dict1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Date\n",
    "start_date = \"2024-10-22\"\n",
    "end_date = \"2025-04-13\"\n",
    "# start_date = \"2023-10-24\"\n",
    "# end_date = \"2024-04-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "#URL to scrape from \n",
    "url = f\"https://www.prosportstransactions.com/basketball/Search/SearchResults.php?Player=&Team=&BeginDate={start_date}&EndDate={end_date}&PlayerMovementChkBx=yes&Submit=Search\"\n",
    "\n",
    "#-------------Scrape web page--------------------------------------\n",
    "\n",
    "#Get URL HTML\n",
    "response = requests.get(url)\n",
    "print(response) # Response [200] means it went through\n",
    "\n",
    "#Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "#-------------Scrape data from the first web page----------------\n",
    "#Read in html as pandas data frame\n",
    "df_first_page = pd.read_html(url,storage_options=header)\n",
    "    \n",
    "#Select table of interest (the first table)\n",
    "df_first_page = df_first_page[0]\n",
    "\n",
    "#Drop first row (column names)\n",
    "df_first_page.drop([0], inplace = True)\n",
    "   \n",
    "#Remove bullet in front of player names\n",
    "df_first_page[2]=df_first_page[2].str[2:] # \"Acquired\" column\n",
    "df_first_page[3]=df_first_page[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "#Modify column titles\n",
    "df_first_page.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "\n",
    "dfa = []\n",
    "#data frame list to hold data for concating later\n",
    "dfa.append(df_first_page)\n",
    "\n",
    "#------------Scrape data from other pages linked at the bottom of the first page------------\n",
    "# Loop over links (skipping the first 4 (not data) and last 4 (\"Next\" and other webpage links))\n",
    "for i in tqdm(range(4,len(soup.findAll('a'))-4)): #'a' tags are for links\n",
    "   \n",
    "    #find all links on webpage and select the i-th link\n",
    "    one_a_tag = soup.findAll('a')[i]\n",
    "    link = one_a_tag['href']\n",
    "    \n",
    "    #Add in the rest of the url\n",
    "    download_url = 'https://www.prosportstransactions.com/basketball/Search/'+ link\n",
    "    # print(download_url)\n",
    "    \n",
    "    #Read html as pandas data frame\n",
    "    dfs = pd.read_html(download_url, storage_options=header)\n",
    "    \n",
    "    #Select table of interest (the first table)\n",
    "    df = dfs[0]\n",
    "    \n",
    "    #Drop first row (column names)\n",
    "    df.drop([0], inplace = True)\n",
    "   \n",
    "    #Remove bullet in front of names\n",
    "    df[2]=df[2].str[2:] # \"Acquired\" column\n",
    "    df[3]=df[3].str[2:] # \"Relinquished\" column\n",
    "    \n",
    "    #Modify column titles\n",
    "    df.columns = ['Date','Team','Acquired','Relinquished','Notes']\n",
    "    #Add a pause to keep web server happy\n",
    "    time.sleep(0.2)\n",
    "    dfa.append(df)\n",
    "df11 = pd.concat(dfa)\n",
    "df = df11.copy()\n",
    "df = df[~df[\"Notes\"].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df[\"Notes\"].str.contains(\"trade\")]\n",
    "df1[\"In\"]=df1['Acquired'].str.split(\"•\")\n",
    "df1[\"Out\"]=df1['Relinquished'].str.split(\"•\")\n",
    "df21 = df1.explode(\"In\")\n",
    "df21 = df21[[\"Date\",\"Team\",\"In\"]]\n",
    "df21.columns = [\"Date\",\"Team\",\"Player\"]\n",
    "df21[\"In\"] = True\n",
    "df21[\"Out\"] = False\n",
    "df22 = df1.explode(\"Out\")\n",
    "df22 = df22[[\"Date\",\"Team\",\"Out\"]]\n",
    "df22.columns = [\"Date\",\"Team\",\"Player\"]\n",
    "df22[\"In\"] = False\n",
    "df22[\"Out\"] = True\n",
    "df2 = pd.concat([df21,df22])\n",
    "df2 = df2[~df2[\"Player\"].str.contains(\"pick\")]\n",
    "df2 = df2[~df2[\"Player\"].str.contains(\"cash\")]\n",
    "df2 = df2[~df2[\"Player\"].str.contains(\"rights\")]\n",
    "df2 = df2.sort_values(by=[\"Date\",\"Player\",\"In\"]).reset_index(drop=True)\n",
    "df2[\"Player\"].loc[df2[\"Player\"].str.contains(\"Kenyon Martin Jr\")] = \"Kenyon Martin Jr.\"\n",
    "df2[\"playerID\"] = df2[\"Player\"].map(pID_dict)\n",
    "\n",
    "df2.loc[df2[\"playerID\"].isna(),\"playerID\"] = df2.loc[df2[\"playerID\"].isna(),\"Player\"].apply(lambda x: get_missing_pId(x, player_dict))\n",
    "df2[\"playerID\"] = df2[\"playerID\"].astype(int)\n",
    "df2[\"teamID\"] = df2[\"Team\"].apply(lambda x: get_missing_tId(x, team_dict))\n",
    "df2.to_parquet(data_DIR + \"trades_in_season_2024.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Team</th>\n",
       "      <th>Player</th>\n",
       "      <th>In</th>\n",
       "      <th>Out</th>\n",
       "      <th>playerID</th>\n",
       "      <th>teamID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Reece Beekman</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1641736</td>\n",
       "      <td>1610612744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Nets</td>\n",
       "      <td>Reece Beekman</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1641736</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>De'Anthony Melton</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1629001</td>\n",
       "      <td>1610612744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Nets</td>\n",
       "      <td>De'Anthony Melton</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1629001</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Nets</td>\n",
       "      <td>Dennis Schröder</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>203471</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Warriors</td>\n",
       "      <td>Dennis Schröder</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>203471</td>\n",
       "      <td>1610612744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Heat</td>\n",
       "      <td>Thomas Bryant</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1628418</td>\n",
       "      <td>1610612748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-12-15</td>\n",
       "      <td>Pacers</td>\n",
       "      <td>Thomas Bryant</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1628418</td>\n",
       "      <td>1610612754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>Maxwell Lewis</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1641721</td>\n",
       "      <td>1610612747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Nets</td>\n",
       "      <td>Maxwell Lewis</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1641721</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Nets</td>\n",
       "      <td>Shake Milton</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1629003</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>Shake Milton</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1629003</td>\n",
       "      <td>1610612747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1626156</td>\n",
       "      <td>1610612747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Nets</td>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1626156</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Nets</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1627827</td>\n",
       "      <td>1610612751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-12-29</td>\n",
       "      <td>Lakers</td>\n",
       "      <td>Dorian Finney-Smith</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1627827</td>\n",
       "      <td>1610612747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date      Team                Player     In    Out  playerID  \\\n",
       "0   2024-12-15  Warriors        Reece Beekman   False   True   1641736   \n",
       "1   2024-12-15      Nets        Reece Beekman    True  False   1641736   \n",
       "2   2024-12-15  Warriors    De'Anthony Melton   False   True   1629001   \n",
       "3   2024-12-15      Nets    De'Anthony Melton    True  False   1629001   \n",
       "4   2024-12-15      Nets      Dennis Schröder   False   True    203471   \n",
       "5   2024-12-15  Warriors      Dennis Schröder    True  False    203471   \n",
       "6   2024-12-15      Heat        Thomas Bryant   False   True   1628418   \n",
       "7   2024-12-15    Pacers        Thomas Bryant    True  False   1628418   \n",
       "8   2024-12-29    Lakers        Maxwell Lewis   False   True   1641721   \n",
       "9   2024-12-29      Nets        Maxwell Lewis    True  False   1641721   \n",
       "10  2024-12-29      Nets          Shake Milton  False   True   1629003   \n",
       "11  2024-12-29    Lakers          Shake Milton   True  False   1629003   \n",
       "12  2024-12-29    Lakers     D'Angelo Russell   False   True   1626156   \n",
       "13  2024-12-29      Nets     D'Angelo Russell    True  False   1626156   \n",
       "14  2024-12-29      Nets  Dorian Finney-Smith   False   True   1627827   \n",
       "15  2024-12-29    Lakers  Dorian Finney-Smith    True  False   1627827   \n",
       "\n",
       "        teamID  \n",
       "0   1610612744  \n",
       "1   1610612751  \n",
       "2   1610612744  \n",
       "3   1610612751  \n",
       "4   1610612751  \n",
       "5   1610612744  \n",
       "6   1610612748  \n",
       "7   1610612754  \n",
       "8   1610612747  \n",
       "9   1610612751  \n",
       "10  1610612751  \n",
       "11  1610612747  \n",
       "12  1610612747  \n",
       "13  1610612751  \n",
       "14  1610612751  \n",
       "15  1610612747  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ub9Z_EQq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
