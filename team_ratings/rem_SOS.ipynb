{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from nbafuns import *\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
    "\n",
    "teams_dict, teams_list = get_teams(league=\"NBA\")\n",
    "box_DIR = \"../data/box/\"\n",
    "img_DIR_T = \"../data/images/teams/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(season=2024,ngames=0):\n",
    "    cols = [\n",
    "        \"gameId\",\n",
    "        \"teamName\",\n",
    "        \"teamId\",\n",
    "        \"offensiveRating\",\n",
    "        \"defensiveRating\",\n",
    "        \"netRating\",\n",
    "        \"possessions\",\n",
    "    ]\n",
    "    df = pd.read_parquet(box_DIR + f\"NBA_Box_T_Adv_{season}.parquet\", columns=cols)\n",
    "    cols = [\"gameId\", \"team\", \"tId\", \"ORtg\", \"DRtg\", \"NRtg\", \"poss\"]\n",
    "    df.columns = cols\n",
    "    df1 = df.groupby(\"gameId\")\n",
    "    df1_1 = df1.nth(0)\n",
    "    df1_2 = df1.nth(1)\n",
    "    df1_1.columns = [\"gameId\"] + [s + \"1\" for s in df1_1.columns if s != \"gameId\"]\n",
    "    df1_2.columns = [\"gameId\"] + [s + \"2\" for s in df1_2.columns if s != \"gameId\"]\n",
    "    df1_3 = pd.merge(df1_1, df1_2, on=\"gameId\")\n",
    "    df1_4 = df1.nth(1)\n",
    "    df1_5 = df1.nth(0)\n",
    "    df1_4.columns = [\"gameId\"] + [s + \"1\" for s in df1_4.columns if s != \"gameId\"]\n",
    "    df1_5.columns = [\"gameId\"] + [s + \"2\" for s in df1_5.columns if s != \"gameId\"]\n",
    "    df1_6 = pd.merge(df1_4, df1_5, on=\"gameId\")\n",
    "    df2 = pd.concat([df1_3, df1_6]).sort_values(by=\"gameId\").reset_index(drop=True)\n",
    "    data1 = df2.copy()\n",
    "    df10 = pd.read_parquet(box_DIR + f\"NBA_Box_T_Base_{season}.parquet\")\n",
    "    if ngames != 0:\n",
    "        df10g = df10.groupby(\"TEAM_NAME\")\n",
    "        df10 = df10g.nth(np.arange(-ngames,0,1)).reset_index(drop=True)\n",
    "    df10[\"HOME\"] = ~df10[\"MATCHUP\"].str.contains(\"@\")\n",
    "    df10[\"tId1\"] = df10[\"TEAM_ID\"]\n",
    "    df10[\"gameId\"] = df10[\"GAME_ID\"]\n",
    "    df11 = (\n",
    "        df10[[\"gameId\", \"tId1\", \"HOME\"]].sort_values(by=\"gameId\").reset_index(drop=True)\n",
    "    )\n",
    "    df11[[\"gameId\", \"tId1\"]] = df11[[\"gameId\", \"tId1\"]].astype(int)\n",
    "    data = pd.merge(data1, df11)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(data, results_adj):\n",
    "    data[\"pts1\"] = data[\"ORtg1\"] * data[\"poss1\"]\n",
    "    data[\"pts2\"] = data[\"DRtg1\"] * data[\"poss1\"]\n",
    "    off_prior = data.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    def_prior = data.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    off_prior[\"OFF\"] = off_prior[\"pts1\"] / off_prior[\"poss1\"]\n",
    "    off_prior = off_prior[[\"tId1\", \"OFF\"]]\n",
    "    def_prior[\"DEF\"] = def_prior[\"pts2\"] / def_prior[\"poss1\"]\n",
    "    def_prior = def_prior[[\"tId1\", \"DEF\"]]\n",
    "    results_net = pd.merge(off_prior, def_prior, on=[\"tId1\"])\n",
    "    results_net[\"NET\"] = results_net[\"OFF\"] - results_net[\"DEF\"]\n",
    "    results_net.rename(columns={\"tId1\": \"tId\"}, inplace=True)\n",
    "    results_net = results_net.astype(float).round(2)\n",
    "    results_net[\"tId\"] = results_net[\"tId\"].astype(int)\n",
    "    ortg_mean = data[\"pts1\"].sum() / data[\"poss1\"].sum()\n",
    "    drtg_mean = data[\"pts2\"].sum() / data[\"poss1\"].sum()\n",
    "    results_adj[\"tId\"] = results_adj[\"tId\"].astype(int)\n",
    "    results_comb = pd.merge(results_net, results_adj, on=[\"tId\"])\n",
    "    results_comb[\"aOFF\"] = results_comb[\"aOFF\"]\n",
    "    results_comb[\"aDEF\"] = results_comb[\"aDEF\"]\n",
    "    results_comb[\"oSOS\"] = results_comb[\"aOFF\"] - results_comb[\"OFF\"]\n",
    "    results_comb[\"dSOS\"] = results_comb[\"DEF\"] - results_comb[\"aDEF\"]\n",
    "    results_comb[\"SOS\"] = results_comb[\"oSOS\"] + results_comb[\"dSOS\"]\n",
    "    results_comb.iloc[:, 1:] = results_comb.iloc[:, 1:].round(1)\n",
    "    results = results_comb[\n",
    "        [\"Team\", \"OFF\", \"oSOS\", \"aOFF\", \"DEF\", \"dSOS\", \"aDEF\", \"NET\", \"SOS\", \"aNET\"]\n",
    "    ]\n",
    "    # results = results_comb[[\"Team\",\"OFF\",\"DEF\",\"NET\",\"aOFF\",\"aDEF\",\"aNET\"]]\n",
    "    results = results.sort_values(by=\"aNET\", ascending=0).reset_index(drop=True)\n",
    "    return results, ortg_mean, drtg_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_teams(row_in, teams, scale):\n",
    "    t1 = row_in[0]\n",
    "    t2 = row_in[1]\n",
    "\n",
    "    rowOut = np.zeros([len(teams) * 2])\n",
    "    rowOut[teams.index(t1)] = scale\n",
    "    rowOut[teams.index(t2) + len(teams)] = scale\n",
    "\n",
    "    return rowOut\n",
    "\n",
    "\n",
    "def convert_to_matricies(possessions, name, teams, scale=1):\n",
    "    # extract only the columns we need\n",
    "    # Convert the columns of player ids into a numpy matrix\n",
    "    stints_x_base = possessions[[\"tId1\", \"tId2\"]].to_numpy()\n",
    "    # Apply our mapping function to the numpy matrix\n",
    "    stint_X_rows = np.apply_along_axis(map_teams, 1, stints_x_base, teams, scale=scale)\n",
    "    # Convert the column of target values into a numpy matrix\n",
    "    stint_Y_rows = possessions[name].to_numpy()\n",
    "\n",
    "    # return matricies and possessions series\n",
    "    return stint_X_rows, stint_Y_rows\n",
    "\n",
    "\n",
    "# Convert lambda value to alpha needed for ridge CV\n",
    "\n",
    "\n",
    "def lambda_to_alpha(lambda_value, samples):\n",
    "    return (lambda_value * samples) / 2.0\n",
    "\n",
    "\n",
    "# Convert RidgeCV alpha back into a lambda value\n",
    "\n",
    "\n",
    "def alpha_to_lambda(alpha_value, samples):\n",
    "    return (alpha_value * 2.0) / samples\n",
    "\n",
    "\n",
    "def calculate_netrtg(train_x, train_y, lambdas, teams_list):\n",
    "    alphas = [lambda_to_alpha(l, train_x.shape[0]) for l in lambdas]\n",
    "    # create a 5 fold CV ridgeCV model. Our target data is not centered at 0, so we want to fit to an intercept.\n",
    "    clf = RidgeCV(alphas=alphas, cv=5, fit_intercept=True)\n",
    "\n",
    "    # fit our training data\n",
    "    model = clf.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "    # convert our list of players into a mx1 matrix\n",
    "    team_arr = np.transpose(np.array(teams_list).reshape(1, len(teams_list)))\n",
    "\n",
    "    # extract our coefficients into the offensive and defensive parts\n",
    "    coef_offensive_array = model.coef_[0 : len(teams_list)][np.newaxis].T\n",
    "    coef_defensive_array = model.coef_[len(teams_list) : 2 * len(teams_list)][\n",
    "        np.newaxis\n",
    "    ].T\n",
    "    # concatenate the offensive and defensive values with the playey ids into a mx3 matrix\n",
    "    team_id_with_coef = np.concatenate(\n",
    "        [team_arr, coef_offensive_array, coef_defensive_array], axis=1\n",
    "    )\n",
    "    # build a dataframe from our matrix\n",
    "    teams_coef = pd.DataFrame(team_id_with_coef)\n",
    "    intercept = model.intercept_\n",
    "    teams_coef.columns = [\"tId\", \"aOFF\", \"aDEF\"]\n",
    "    teams_coef[\"aNET\"] = teams_coef[\"aOFF\"] - teams_coef[\"aDEF\"]\n",
    "    teams_coef[\"aOFF\"] = teams_coef[\"aOFF\"] + intercept\n",
    "    teams_coef[\"aDEF\"] = teams_coef[\"aDEF\"] + intercept\n",
    "    teams_coef[\"Team\"] = teams_coef[\"tId\"].map(teams_dict)\n",
    "    results = teams_coef[[\"tId\", \"Team\", \"aOFF\", \"aDEF\", \"aNET\"]]\n",
    "    results = results.sort_values(by=[\"aNET\"], ascending=False).reset_index(drop=True)\n",
    "    return results, model, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2024\n",
    "ngames = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datar = get_ratings(season,ngames=0)\n",
    "train_x, train_y = convert_to_matricies(datar, \"ORtg1\", teams_list, scale=1 / 2)\n",
    "n = 1.5*0.1\n",
    "# n = 1.5/2*0.1\n",
    "lambdas_net = [0.01 * n, 0.05 * n, 0.1 * n]\n",
    "# lambdas_net = [10/3]\n",
    "results_adj, model, intercept = calculate_netrtg(\n",
    "    train_x, train_y, lambdas_net, teams_list\n",
    ")\n",
    "results, ortg_mean, drtg_mean = process_results(datar, results_adj)\n",
    "results.index = results.index +1\n",
    "print(intercept)\n",
    "# results.head(5)\n",
    "# results.sort_values(by=\"aOFF\",ascending=0)\n",
    "# results.sort_values(by=\"aDEF\",ascending=1)\n",
    "# cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"https://stats.nba.com/stats/scheduleleaguev2?Season=2024-25&LeagueID=00\"\n",
    "\"http://data.nba.com/data/10s/v2015/json/mobile_teams/nba/2018/league/00_full_schedule.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(f\"http://data.nba.com/data/10s/v2015/json/mobile_teams/nba/{season}/league/00_full_schedule.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = r.json()\n",
    "gid, tid_v, tid_h, game_date = [], [], [], []\n",
    "for mo in rj['lscd']:\n",
    "    for g in mo['mscd']['g']:\n",
    "        gid.append(g['gid'])\n",
    "        tid_v.append(g['v']['tid'])\n",
    "        tid_h.append(g['h']['tid'])\n",
    "        game_date.append(g['gdte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame({'gid':gid,'tId_h':tid_h,'tId_v':tid_v,'game_date':game_date })\n",
    "dfs[\"game_date\"] = pd.to_datetime(dfs[\"game_date\"])\n",
    "dfs = dfs[dfs[\"gid\"].str[:3] == \"002\"]\n",
    "dfs = dfs.sort_values([\"game_date\",\"gid\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = datetime.today()\n",
    "dfsf = dfs.query(f\"game_date >= '{ty.strftime(\"%b %d, %Y\")}'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = dfsf[[\"gid\", \"tId_h\", \"tId_v\",\"game_date\"]]\n",
    "df11[\"home\"] = True\n",
    "df11 = df11.rename(columns={\"tId_h\":\"tId\",\"tId_v\":\"tId2\"})\n",
    "df12 = dfsf[[\"gid\", \"tId_v\", \"tId_h\",\"game_date\"]]\n",
    "df12[\"home\"] = False\n",
    "df12 = df12.rename(columns={\"tId_h\":\"tId2\",\"tId_v\":\"tId\"})\n",
    "df1 = pd.concat([df11,df12]).sort_values([\"game_date\",\"gid\",\"home\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = results_adj[[\"tId\",\"aNET\"]]\n",
    "dfn.columns = [\"tId2\",\"aNET\"]\n",
    "df2  = pd.merge(df1,dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.groupby(\"tId\")[[\"aNET\"]].mean()\n",
    "df3 = df3.reset_index()\n",
    "df3[\"Team\"] = df3[\"tId\"].map(teams_dict)\n",
    "df3 = df3.rename(columns={\"aNET\":\"oNET\"})\n",
    "dfn = results_adj[[\"tId\",\"aNET\"]]\n",
    "df4 = pd.merge(df3,dfn)\n",
    "df4 = df4[[\"tId\",\"Team\",\"aNET\",\"oNET\"]].sort_values(\"oNET\",ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(\"../data/NBA_teams_colors_logos.csv\")\n",
    "df_teams = df_teams.rename(columns={\"nameTeam\": \"Team\"})\n",
    "df_teams = df_teams[[\"Team\",\"colorsTeam\"]]\n",
    "data = pd.merge(df4, df_teams)\n",
    "data[\"image\"] = img_DIR_T + data[\"Team\"] + \".png\"\n",
    "teams = data[\"Team\"].to_list()\n",
    "teams.reverse()\n",
    "data[\"Team\"] = pd.Categorical(data[\"Team\"],categories=teams,ordered=True)\n",
    "today = datetime.today().strftime(\"%B %d, %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    ggplot(data)\n",
    "    + aes(x=\"Team\",y=\"oNET\",fill=\"colorsTeam\",image=\"image\")\n",
    "    + geom_col(alpha=0.7,show_legend=False)\n",
    "    + geom_image(aes(y=0),size=0.06)\n",
    "    + coord_flip()\n",
    "    + scale_color_identity(aesthetics=[\"fill\"])\n",
    "    + theme_xkcd(base_size=15)\n",
    "    + theme(\n",
    "        figure_size=(10,10),\n",
    "        text=element_text(family=[\"Comic Sans MS\"])\n",
    "    )\n",
    "    + pnba\n",
    "    + labs(\n",
    "        title=f\"Remaining Strength of Schedule (SoS) as of {today}\",\n",
    "        subtitle=\"Opponent Net Rating is Adjusted for previous SoS\",\n",
    "        x=\"\",\n",
    "        y=\"Remaining Opponent Net Rating\"\n",
    "    )\n",
    ")\n",
    "p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dav-ub9Z_EQq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
