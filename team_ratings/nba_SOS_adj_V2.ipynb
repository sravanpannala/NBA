{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Adjust Offensive, Defensive and Net Ratings for Strength of Schedule\n",
    "## Trying more stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import os, sys\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "from nbafuns import *\n",
    "\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# model = make_pipeline(StandardScaler(with_mean=False), _RidgeGCV())\n",
    "\n",
    "teams_dict, teams_list = get_teams(league=\"NBA\")\n",
    "box_DIR = \"../fdata/boxscores_team/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_decay(X):\n",
    "    X = X.to_numpy()\n",
    "    y = np.zeros(np.size(X))\n",
    "    for i,x in enumerate(X):\n",
    "        yj=0\n",
    "        for j in range(i):\n",
    "            xj = x-X[j]\n",
    "            yj += np.exp(-(x-X[j]))\n",
    "        y[i] = yj\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(season=2023,rest = 1):\n",
    "    df1 = pd.read_csv(box_DIR + f\"NBA_BoxScores_Adv_{season}.csv\")\n",
    "    df1 = df1.rename(\n",
    "        columns={\n",
    "            \"offensiveRating\": \"ORtg\",\n",
    "            \"defensiveRating\": \"DRtg\",\n",
    "            \"netRating\": \"NRtg\",\n",
    "            \"possessions\": \"poss\",\n",
    "        }\n",
    "    )\n",
    "    cols = [\"gameId\", \"teamId\", \"ORtg\", \"DRtg\", \"NRtg\", \"poss\"]\n",
    "    df1 = df1[cols]\n",
    "    df1[\"Win\"] = df1[\"NRtg\"] > 0\n",
    "    df1[\"Loss\"] = df1[\"NRtg\"] < 0\n",
    "    df2 = pd.read_csv(box_DIR + f\"NBA_BoxScores_Standard_{season}.csv\")\n",
    "    df2 = df2.rename(\n",
    "        columns={\n",
    "            \"GAME_ID\": \"gameId\",\n",
    "            \"TEAM_ID\": \"teamId\",\n",
    "            \"TEAM_ABBREVIATION\": \"teamTricode\",\n",
    "            \"GAME_DATE\": \"gameDate\",\n",
    "            \"TEAM_NAME\": \"teamName\",\n",
    "            \"MATCHUP\": \"Matchup\",\n",
    "        }\n",
    "    )\n",
    "    cols2 = [\"gameId\", \"teamId\", \"teamTricode\", \"gameDate\",\"Matchup\"]\n",
    "    df2 = df2[cols2]\n",
    "    df2[\"Home\"] = np.where(~df2[\"Matchup\"].str.contains(\"@\"), 1, 0)\n",
    "    df2[\"Away\"] = np.where(df2[\"Matchup\"].str.contains(\"@\"), 1, 0)\n",
    "    df2[\"gameId\"] = df2[\"gameId\"].astype(int)\n",
    "    df3 = pd.merge(df2, df1, on=[\"gameId\", \"teamId\"])\n",
    "    df3 = df3.rename(columns={\"gameDate\": \"Date\"})\n",
    "    df3[\"Date\"] = pd.to_datetime(df3[\"Date\"], format=\"%Y-%m-%d\")\n",
    "    df4 = df3.sort_values(by=[\"teamTricode\",\"Date\"])\n",
    "    df4[\"Date_D\"] = (df4[\"Date\"] - df4[\"Date\"].iloc[0]).dt.days\n",
    "    teams = df4[\"teamTricode\"].unique()\n",
    "    dfa = []\n",
    "    for team in teams:\n",
    "        df5 = df4[df4[\"teamTricode\"] == team].reset_index(drop=True)\n",
    "        df5[\"Rest\"] = time_decay(df5['Date_D'])\n",
    "        df5[\"Rest\"] = df5[\"Rest\"].round(5)\n",
    "        dfa.append(df5)\n",
    "    df5 = pd.concat(dfa)\n",
    "    df5 = df5.reset_index(drop=True)\n",
    "    cols = [\n",
    "        \"gameId\",\n",
    "        \"teamTricode\",\n",
    "        \"teamId\",\n",
    "        \"ORtg\",\n",
    "        \"DRtg\",\n",
    "        \"NRtg\",\n",
    "        \"poss\",\n",
    "        \"Home\",\n",
    "        \"Away\",\n",
    "        \"Rest\",\n",
    "    ]\n",
    "    df6 = df5[cols]\n",
    "    df6.iloc[:, 1:] = df6.iloc[:, 1:].astype(str)\n",
    "    df7 = df6.groupby(\"gameId\")[cols[1:]].agg(\", \".join).reset_index()\n",
    "    df8 = df7.copy()\n",
    "    df8[[\"team1\", \"team2\"]] = df7[\"teamTricode\"].str.split(\",\", expand=True)\n",
    "    df8[[\"tId1\", \"tId2\"]] =   df7[\"teamId\"].str.split(\",\", expand=True)\n",
    "    df8[[\"ORtg1\", \"ORtg2\"]] = df7[\"ORtg\"].str.split(\",\", expand=True)\n",
    "    df8[[\"DRtg1\", \"DRtg2\"]] = df7[\"DRtg\"].str.split(\",\", expand=True)\n",
    "    df8[[\"NRtg1\", \"NRtg2\"]] = df7[\"NRtg\"].str.split(\",\", expand=True)\n",
    "    df8[[\"poss1\", \"poss2\"]] = df7[\"poss\"].str.split(\",\", expand=True)\n",
    "    df8[[\"rest1\", \"rest2\"]] = df7[\"Rest\"].str.split(\",\", expand=True)\n",
    "    df8[[\"home1\", \"home2\"]] = df7[\"Home\"].str.split(\",\", expand=True)\n",
    "    # df8[[\"away1\", \"away2\"]] = df7[\"Away\"].str.split(\",\", expand=True)\n",
    "    df8 = df8.drop(columns=cols[1:])\n",
    "    df9 = df7.copy()\n",
    "    df9[[\"team2\", \"team1\"]] = df7[\"teamTricode\"].str.split(\",\", expand=True)\n",
    "    df9[[\"tId2\", \"tId1\"]] =   df7[\"teamId\"].str.split(\",\", expand=True)\n",
    "    df9[[\"ORtg2\", \"ORtg1\"]] = df7[\"ORtg\"].str.split(\",\", expand=True)\n",
    "    df9[[\"DRtg2\", \"DRtg1\"]] = df7[\"DRtg\"].str.split(\",\", expand=True)\n",
    "    df9[[\"NRtg2\", \"NRtg1\"]] = df7[\"NRtg\"].str.split(\",\", expand=True)\n",
    "    df9[[\"poss2\", \"poss1\"]] = df7[\"poss\"].str.split(\",\", expand=True)\n",
    "    df9[[\"rest2\", \"rest1\"]] = df7[\"Rest\"].str.split(\",\", expand=True)\n",
    "    df9[[\"home2\", \"home1\"]] = df7[\"Home\"].str.split(\",\", expand=True)\n",
    "    # df9[[\"away2\", \"away1\"]] = df7[\"Away\"].str.split(\",\", expand=True)\n",
    "    df9 = df9.drop(columns=cols[1:])\n",
    "    df10 = pd.concat([df8, df9]).sort_values(by=\"gameId\").reset_index(drop=True)\n",
    "    cols = df10.columns\n",
    "    df10[cols[3:5]]   = df10[cols[3:5]].astype(int)\n",
    "    df10[cols[5:15]]  = df10[cols[5:15]].astype(float)\n",
    "    df10[cols[15:17]] = df10[cols[15:17]].astype(int)\n",
    "    df10[cols[15:17]] = df10[cols[15:17]].astype(bool)\n",
    "    data = df10.copy()\n",
    "    # Old Version of Prior with using Home/Away Off rating + rest\n",
    "    # and Home/Away Def rating + rest : wasn't working well\n",
    "    # df1 = data.query(\"home1\").reset_index(drop=True)\n",
    "    # df1[\"pts1\"] = df1[\"ORtg1\"] * df1[\"poss1\"] \n",
    "    # df1[\"pts2\"] = df1[\"DRtg1\"] * df1[\"poss1\"]\n",
    "    # off_prior = df1.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    # def_prior = df1.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    # off_prior[\"OFF\"] = off_prior[\"pts1\"] / off_prior[\"poss1\"]\n",
    "    # off_prior[\"OFF\"] = off_prior[\"OFF\"].round(3)\n",
    "    # off_prior = off_prior[[\"tId1\", \"OFF\"]]\n",
    "    # def_prior[\"DEF\"] = def_prior[\"pts2\"] / def_prior[\"poss1\"]\n",
    "    # def_prior[\"DEF\"] = def_prior[\"DEF\"].round(3)\n",
    "    # def_prior = def_prior[[\"tId1\", \"DEF\"]]\n",
    "    # def_prior = def_prior.rename(columns={\"tId1\":\"tId2\"})\n",
    "    # df1 = pd.merge(df1,off_prior, on=\"tId1\")\n",
    "    # df1 = pd.merge(df1,def_prior, on=\"tId2\")\n",
    "    # df2 = data.query(\"home2\").reset_index(drop=True)\n",
    "    # df2[\"pts1\"] = df2[\"ORtg1\"] * df2[\"poss1\"] \n",
    "    # df2[\"pts2\"] = df2[\"DRtg1\"] * df2[\"poss1\"]\n",
    "    # off_prior = df2.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    # def_prior = df2.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    # off_prior[\"OFF\"] = off_prior[\"pts1\"] / off_prior[\"poss1\"]\n",
    "    # off_prior[\"OFF\"] = off_prior[\"OFF\"].round(3)\n",
    "    # off_prior = off_prior[[\"tId1\", \"OFF\"]]\n",
    "    # def_prior[\"DEF\"] = def_prior[\"pts2\"] / def_prior[\"poss1\"]\n",
    "    # def_prior[\"DEF\"] = def_prior[\"DEF\"].round(3)\n",
    "    # def_prior = def_prior[[\"tId1\", \"DEF\"]]\n",
    "    # def_prior = def_prior.rename(columns={\"tId1\":\"tId2\"})\n",
    "    # df2 = pd.merge(df2,off_prior, on=\"tId1\")\n",
    "    # df2 = pd.merge(df2,def_prior, on=\"tId2\")\n",
    "    # data= pd.concat([df1,df2])\n",
    "    # data = data.drop(columns = [\"pts1\",\"pts2\"])\n",
    "    # data[\"OFF_P\"] = (data[\"OFF\"] - 1*data[\"rest1\"]).round(3)\n",
    "    # data[\"DEF_P\"] = (data[\"DEF\"] + 1*data[\"rest2\"]).round(3)\n",
    "    # # data[\"Prior\"] = (0.5*(data[\"OFF_P\"]+data[\"DEF_P\"])).round(3)\n",
    "    # data[\"Prior\"] = (data[\"OFF\"]).round(3)\n",
    "    # data = data.drop(columns=[\"OFF\",\"DEF\",\"OFF_P\",\"DEF_P\"])\n",
    "\n",
    "    # Prior with using HCA of Off Rating + rest\n",
    "    # and HCA of rating + rest l\n",
    "    # df1 = data.copy()\n",
    "    # df1[\"pts1\"] = df1[\"ORtg1\"] * df1[\"poss1\"] \n",
    "    # df1[\"pts2\"] = df1[\"DRtg1\"] * df1[\"poss1\"]\n",
    "    # off_p = df1.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    # def_p = df1.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    # off_p[\"OFF\"] = off_p[\"pts1\"] / off_p[\"poss1\"]\n",
    "    # off_p[\"OFF\"] = off_p[\"OFF\"].round(3)\n",
    "    # off_p_all = off_p[[\"tId1\", \"OFF\"]]\n",
    "    # def_p[\"DEF\"] = def_p[\"pts2\"] / def_p[\"poss1\"]\n",
    "    # def_p[\"DEF\"] = def_p[\"DEF\"].round(3)\n",
    "    # def_p_all = def_p[[\"tId1\", \"DEF\"]]\n",
    "    # df1 = data.query(\"home1\").reset_index(drop=True)\n",
    "    # df1[\"pts1\"] = df1[\"ORtg1\"] * df1[\"poss1\"] \n",
    "    # df1[\"pts2\"] = df1[\"DRtg1\"] * df1[\"poss1\"]\n",
    "    # off_p = df1.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    # def_p = df1.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    # off_p[\"OFF\"] = off_p[\"pts1\"] / off_p[\"poss1\"]\n",
    "    # off_p[\"OFF\"] = off_p[\"OFF\"].round(3)\n",
    "    # off_p_home = off_p[[\"tId1\", \"OFF\"]]\n",
    "    # def_p[\"DEF\"] = def_p[\"pts2\"] / def_p[\"poss1\"]\n",
    "    # def_p[\"DEF\"] = def_p[\"DEF\"].round(3)\n",
    "    # def_p_home = def_p[[\"tId1\", \"DEF\"]]\n",
    "    # off_adv= pd.merge(off_p_home,off_p_all,on=\"tId1\")\n",
    "    # def_adv= pd.merge(def_p_home,def_p_all,on=\"tId1\")\n",
    "    # off_adv[\"OHCA\"] = off_adv[\"OFF_x\"] - off_adv[\"OFF_y\"]\n",
    "    # def_adv[\"DHCA\"] = def_adv[\"DEF_x\"] - def_adv[\"DEF_y\"]\n",
    "    # def_adv = def_adv.rename(columns={\"tId1\":\"tId2\"})\n",
    "    # off_adv = off_adv.drop(columns=[\"OFF_x\",\"OFF_y\"])\n",
    "    # def_adv = def_adv.drop(columns=[\"DEF_x\",\"DEF_y\"])\n",
    "    # data = pd.merge(data,off_adv,on=\"tId1\")\n",
    "    # data = pd.merge(data,def_adv,on=\"tId2\")\n",
    "\n",
    "    # data[\"Prior\"] = (- 10* data[\"rest1\"]  \n",
    "    #                  + 10* data[\"rest2\"] \n",
    "    #                  + np.where(data[\"home1\"],1,-1)*data[\"OHCA\"]\n",
    "    #                  + np.where(data[\"home2\"],1,-1)*data[\"DHCA\"]\n",
    "    #             ).round(3)\n",
    "    \n",
    "    # Prior with using league avg HCA + rest\n",
    "    df1 = data.copy()\n",
    "    df1[\"pts1\"] = df1[\"ORtg1\"] * df1[\"poss1\"] \n",
    "    df1[\"pts2\"] = df1[\"DRtg1\"] * df1[\"poss1\"]\n",
    "    off_all = (df1[\"pts1\"].sum() / df1[\"poss1\"].sum()).round(3)\n",
    "    def_all = (df1[\"pts2\"].sum() / df1[\"poss1\"].sum()).round(3)\n",
    "    df1 = data.query(\"home1\").reset_index(drop=True)\n",
    "    df1[\"pts1\"] = df1[\"ORtg1\"] * df1[\"poss1\"] \n",
    "    df1[\"pts2\"] = df1[\"DRtg1\"] * df1[\"poss1\"]\n",
    "    off_home = (df1[\"pts1\"].sum() / df1[\"poss1\"].sum()).round(3)\n",
    "    def_home = (df1[\"pts2\"].sum() / df1[\"poss1\"].sum()).round(3)\n",
    "    off_adv = off_home - off_all\n",
    "    def_adv = def_home - def_all\n",
    "    data[\"Prior\"] = (- rest* data[\"rest1\"]  \n",
    "                     + rest* data[\"rest2\"] \n",
    "                     + np.where(data[\"home1\"],1,-1)*off_adv\n",
    "                     + np.where(data[\"home2\"],1,-1)*def_adv\n",
    "                ).round(3)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(data, results_adj):\n",
    "    data[\"pts1\"] = data[\"ORtg1\"] * data[\"poss1\"]\n",
    "    data[\"pts2\"] = data[\"DRtg1\"] * data[\"poss1\"]\n",
    "    off_prior = data.groupby([\"tId1\"])[[\"poss1\", \"pts1\"]].agg(\"sum\").reset_index()\n",
    "    def_prior = data.groupby([\"tId1\"])[[\"poss1\", \"pts2\"]].agg(\"sum\").reset_index()\n",
    "    off_prior[\"OFF\"] = off_prior[\"pts1\"] / off_prior[\"poss1\"]\n",
    "    off_prior = off_prior[[\"tId1\", \"OFF\"]]\n",
    "    def_prior[\"DEF\"] = def_prior[\"pts2\"] / def_prior[\"poss1\"]\n",
    "    def_prior = def_prior[[\"tId1\", \"DEF\"]]\n",
    "    results_net = pd.merge(off_prior, def_prior, on=[\"tId1\"])\n",
    "    results_net[\"NET\"] = results_net[\"OFF\"] - results_net[\"DEF\"]\n",
    "    results_net.rename(columns={\"tId1\": \"tId\"}, inplace=True)\n",
    "    results_net = results_net.astype(float).round(2)\n",
    "    results_net[\"tId\"] = results_net[\"tId\"].astype(int)\n",
    "    ortg_mean = data[\"pts1\"].sum() / data[\"poss1\"].sum()\n",
    "    drtg_mean = data[\"pts2\"].sum() / data[\"poss1\"].sum()\n",
    "    results_adj[\"tId\"] = results_adj[\"tId\"].astype(int)\n",
    "    results_comb = pd.merge(results_net, results_adj, on=[\"tId\"])\n",
    "    results_comb[\"aOFF\"] = results_comb[\"aOFF\"] #+ results_comb[\"OFF\"]\n",
    "    results_comb[\"aDEF\"] = results_comb[\"aDEF\"] #+ results_comb[\"DEF\"]\n",
    "    results_comb[\"aNET\"] = results_comb[\"aNET\"] #+ results_comb[\"NET\"]\n",
    "    results_comb[\"oSOS\"] = results_comb[\"aOFF\"] - results_comb[\"OFF\"]\n",
    "    results_comb[\"dSOS\"] = results_comb[\"DEF\"] - results_comb[\"aDEF\"]\n",
    "    results_comb[\"SOS\"] = results_comb[\"oSOS\"] + results_comb[\"dSOS\"]\n",
    "    results_comb.iloc[:, 1:] = results_comb.iloc[:, 1:].round(1)\n",
    "    results = results_comb[\n",
    "        [\"Team\", \"OFF\", \"oSOS\", \"aOFF\", \"DEF\", \"dSOS\", \"aDEF\", \"NET\", \"SOS\", \"aNET\"]\n",
    "    ]\n",
    "    # results = results_comb[[\"Team\",\"OFF\",\"DEF\",\"NET\",\"aOFF\",\"aDEF\",\"aNET\"]]\n",
    "    results = results.sort_values(by=\"aNET\", ascending=0).reset_index(drop=True)\n",
    "    return results, ortg_mean, drtg_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_teams(row_in, teams, scale):\n",
    "    t1 = row_in[0]\n",
    "    t2 = row_in[1]\n",
    "\n",
    "    rowOut = np.zeros([len(teams) * 2])\n",
    "    rowOut[teams.index(t1)] = scale\n",
    "    rowOut[teams.index(t2) + len(teams)] = scale\n",
    "\n",
    "    return rowOut\n",
    "\n",
    "\n",
    "def convert_to_matricies(possessions, name, teams, prior, scale=1):\n",
    "    # extract only the columns we need\n",
    "    # Convert the columns of player ids into a numpy matrix\n",
    "    stints_x_base = possessions[[\"tId1\", \"tId2\"]].to_numpy()\n",
    "    # Apply our mapping function to the numpy matrix\n",
    "    stint_X_rows = np.apply_along_axis(map_teams, 1, stints_x_base, teams, scale=scale)\n",
    "    # Convert the column of target values into a numpy matrix\n",
    "    # Convert the column of target values into a numpy matrix\n",
    "    stint_Y_rows_before = possessions[name].to_numpy()\n",
    "    stint_Y_rows = stint_Y_rows_before - prior\n",
    "\n",
    "    # return matricies and possessions series\n",
    "    return stint_X_rows, stint_Y_rows\n",
    "\n",
    "\n",
    "# Convert lambda value to alpha needed for ridge CV\n",
    "\n",
    "\n",
    "def lambda_to_alpha(lambda_value, samples):\n",
    "    return (lambda_value * samples) / 2.0\n",
    "\n",
    "\n",
    "# Convert RidgeCV alpha back into a lambda value\n",
    "\n",
    "\n",
    "def alpha_to_lambda(alpha_value, samples):\n",
    "    return (alpha_value * 2.0) / samples\n",
    "\n",
    "\n",
    "def calculate_netrtg(train_x, train_y, lambdas, teams_list, prior):\n",
    "    alphas = [lambda_to_alpha(l, train_x.shape[0]) for l in lambdas]\n",
    "    # create a 5 fold CV ridgeCV model. Our target data is not centered at 0, so we want to fit to an intercept.\n",
    "    clf = RidgeCV(alphas=alphas, cv=5, fit_intercept=True)\n",
    "\n",
    "    # fit our training data\n",
    "    model = clf.fit(\n",
    "        train_x,\n",
    "        train_y,\n",
    "    )\n",
    "\n",
    "    # convert our list of players into a mx1 matrix\n",
    "    team_arr = np.transpose(np.array(teams_list).reshape(1, len(teams_list)))\n",
    "\n",
    "    # extract our coefficients into the offensive and defensive parts\n",
    "    coef_ = model.coef_ \n",
    "    coef_offensive_array = coef_[0 : len(teams_list)][np.newaxis].T\n",
    "    coef_defensive_array = coef_[len(teams_list) : 2 * len(teams_list)][\n",
    "        np.newaxis\n",
    "    ].T\n",
    "    # concatenate the offensive and defensive values with the playey ids into a mx3 matrix\n",
    "    team_id_with_coef = np.concatenate(\n",
    "        [team_arr, coef_offensive_array, coef_defensive_array], axis=1\n",
    "    )\n",
    "    # build a dataframe from our matrix\n",
    "    teams_coef = pd.DataFrame(team_id_with_coef)\n",
    "    intercept = model.intercept_\n",
    "    teams_coef.columns = [\"tId\", \"aOFF\", \"aDEF\"]\n",
    "    teams_coef[\"aNET\"] = teams_coef[\"aOFF\"] - teams_coef[\"aDEF\"]\n",
    "    teams_coef[\"aOFF\"] = teams_coef[\"aOFF\"] + intercept\n",
    "    teams_coef[\"aDEF\"] = teams_coef[\"aDEF\"] + intercept\n",
    "    teams_coef[\"Team\"] = teams_coef[\"tId\"].map(teams_dict)\n",
    "    results = teams_coef[[\"tId\", \"Team\", \"aOFF\", \"aDEF\", \"aNET\"]]\n",
    "    results = results.sort_values(by=[\"aNET\"], ascending=False).reset_index(drop=True)\n",
    "    return results, model, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seasons = np.arange(2010,2023,1).astype(str)\n",
    "# dfa = []\n",
    "# for season in seasons:\n",
    "#     df = get_ratings(season)\n",
    "#     dfa.append(df)\n",
    "# data = pd.concat(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_ratings(2023, rest=10)\n",
    "prior = data[\"Prior\"].to_numpy()\n",
    "train_x, train_y = convert_to_matricies(data, \"ORtg1\", teams_list, prior, scale = 1/2)\n",
    "n = 1.5\n",
    "lambdas_net = [0.01 * n, 0.05 * n, 0.1 * n]\n",
    "results_adj, model, intercept = calculate_netrtg(\n",
    "    train_x, train_y, lambdas_net, teams_list, prior\n",
    ")\n",
    "results, ortg_mean, drtg_mean = process_results(data, results_adj)\n",
    "results.index = results.index +1\n",
    "# results.to_csv(\"./NBA_Adj_Ratings.csv\",index=False)\n",
    "print(intercept)\n",
    "# results.head(5)\n",
    "# results.sort_values(by=\"aOFF\",ascending=0)\n",
    "# results.sort_values(by=\"aDEF\",ascending=1)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(\"SOS\",ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xcvxcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = \"NET\"\n",
    "# var1 = \"OFF\"\n",
    "# var1 = \"DEF\"\n",
    "var2 = \"a\" + var1\n",
    "slope, intercept, r, p, sterr = scipy.stats.linregress(x=results[var1], y=results[var2])\n",
    "r2 = r**2\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "fig = sns.regplot(\n",
    "    x=var1,\n",
    "    y=var2,\n",
    "    data=results,\n",
    "    color=\"black\",\n",
    "    scatter_kws={\"color\": \"tab:blue\"},\n",
    "    ax=ax,\n",
    ")\n",
    "ax.text(0.05, 0.9, r\"$r^2=$\" + f\"{round(r2,4)}\", transform=ax.transAxes)\n",
    "ax.set_title(\"Adjusted Net Ratings vs Unadjusted\")\n",
    "plt.savefig(\"../figs/team_leaders/aNET_R2_1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"OFF_R\"] = results[\"OFF\"].rank(ascending=False).astype(int)\n",
    "results[\"DEF_R\"] = results[\"DEF\"].rank(ascending=True).astype(int)\n",
    "results[\"NET_R\"] = results[\"NET\"].rank(ascending=False).astype(int)\n",
    "results[\"aOFF_R\"] = results[\"aOFF\"].rank(ascending=False).astype(int)\n",
    "results[\"aDEF_R\"] = results[\"aDEF\"].rank(ascending=True).astype(int)\n",
    "results[\"aNET_R\"] = results[\"aNET\"].rank(ascending=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.read_csv(\"../data/NBA_teams_colors_logos.csv\")\n",
    "df_teams = df_teams.rename(columns={\"nameTeam\": \"Team\"})\n",
    "results_plot = pd.merge(results, df_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results_plot\n",
    "results <- results_plot\n",
    "library(tidyverse)\n",
    "library(ggimage)\n",
    "library(ggrepel)\n",
    "theme_owen <- function() {\n",
    "  theme_minimal(base_size = 16, base_family = \"Consolas\") %+replace%\n",
    "    theme(\n",
    "      panel.grid.minor = element_blank(),\n",
    "      plot.background = element_rect(fill = \"ghostwhite\", color = \"ghostwhite\")\n",
    "    )\n",
    "}\n",
    "p <- ggplot(\n",
    "  results,\n",
    "  aes(x = aOFF, y = aDEF, label = paste0(\"#\", aNET_R, \" Net\"))\n",
    ") +\n",
    "  # geom_point(aes(size = aNRtg_Rank)) +\n",
    "  scale_y_reverse() +\n",
    "  geom_hline(aes(yintercept = mean(aOFF)), color = \"black\") +\n",
    "  geom_vline(aes(xintercept = mean(aDEF)), color = \"black\") +\n",
    "  # geom_abline(intercept = 222, slope = -1, color = \"black\") +\n",
    "  geom_abline(slope = -1,color=\"black\")+\n",
    "  geom_image(\n",
    "    aes(\n",
    "      x = aOFF, y = aDEF,\n",
    "      image = urlThumbnailTeam\n",
    "    ),\n",
    "    size = 0.1\n",
    "  ) +\n",
    "  # geom_text(nudge_x = 1.3, nudge_y = 0, size = 6,check_overlap = TRUE) +\n",
    "  geom_text_repel(nudge_x = 1.1, nudge_y = 0.5,size=6,min.segment.length=10) +\n",
    "  # geom_label(nudge_x = 1.3, nudge_y = 0, size = 6) +\n",
    "  theme_owen() +\n",
    "  theme(\n",
    "    plot.title.position = \"plot\",\n",
    "    plot.title = element_text(face = \"bold\", size = 24, hjust = 0.5),\n",
    "    plot.margin = margin(10, 10, 15, 10),\n",
    "    plot.subtitle = element_text(size = 18),\n",
    "    plot.caption = element_text(size = 14)\n",
    "  ) +\n",
    "  theme(\n",
    "    axis.text.x = element_text(size = 14, face = \"bold\", color = \"black\"),\n",
    "    axis.text.y = element_text(size = 14, face = \"bold\", color = \"black\"),\n",
    "    axis.title.x = element_text(size = 18, face = \"bold\", colour = \"black\"),\n",
    "    axis.title.y = element_text(size = 18, face = \"bold\", colour = \"black\")\n",
    "  ) +\n",
    "  labs(\n",
    "    title = paste0(\"Adjusted Efficiency Landscape as of \", format(Sys.Date(), format = \"%B %d, %Y\")),\n",
    "    x = \"Adjusted Offensive Rating\", y = \"Adjusted Defensive Rating\",\n",
    "    subtitle = \"Net Ratings here are adjusted for Strength of Schedule\",\n",
    "    caption = \"@SravanNBA\"\n",
    "  )\n",
    "ggsave(\"../figs/team_ratings/Adjusted_TRatings.png\", p, w = 10 * 1.5, h = 8 * 1.5, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = results[\n",
    "    [\"Team\", \"aOFF_R\", \"aDEF_R\", \"aNET_R\", \"OFF_R\", \"DEF_R\", \"NET_R\"]\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[\"aOFF_m\"] = r1[\"aOFF_R\"] - r1[\"OFF_R\"]\n",
    "r1[\"aDEF_m\"] = r1[\"aDEF_R\"] - r1[\"DEF_R\"]\n",
    "r1[\"aNET_m\"] = r1[\"aNET_R\"] - r1[\"NET_R\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r1[\n",
    "    [\"Team\", \"aOFF_R\", \"aOFF_m\", \"aDEF_R\", \"aDEF_m\", \"aNET_R\", \"aNET_m\"]\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i r2\n",
    "library(tidyverse)\n",
    "library(gt)\n",
    "df <- r2\n",
    "df %>% \n",
    "  gt()%>%\n",
    "  tab_header(\n",
    "    title = md(\"**NBA Adjusted Rating Movement 2023-24**\"),\n",
    "    subtitle = \"R: Rank, M:Movement\" \n",
    "    ) %>%\n",
    "    data_color(columns = c(aOFF_m,aDEF_m,aNET_m), palette = c(\"red\", \"green\")) %>%\n",
    "    cols_align(align = \"center\",columns = c(aOFF_R,aOFF_m,aDEF_R,aDEF_m,aNET_R,aNET_m))  %>%\n",
    "    cols_label(\n",
    "      aOFF_R = \"R\", aDEF_R = \"R\", aNET_R = \"R\",\n",
    "      aOFF_m = \"M\", aDEF_m = \"M\", aNET_m = \"M\"\n",
    "    ) %>%\n",
    "    tab_spanner(\n",
    "      label = \"OFF\",\n",
    "      columns = c(aOFF_R, aOFF_m)\n",
    "    ) %>%\n",
    "    tab_spanner(\n",
    "      label = \"DEF\",\n",
    "      columns = c(aDEF_R, aDEF_m)\n",
    "    ) %>%\n",
    "    tab_spanner(\n",
    "      label = \"NET\",\n",
    "      columns = c(aNET_R, aNET_m)\n",
    "    ) %>%\n",
    "    tab_options(\n",
    "        table.background.color = \"floralwhite\",\n",
    "        column_labels.font.size = 12,\n",
    "        column_labels.font.weight = 'bold',\n",
    "        row_group.font.weight = 'bold',\n",
    "        row_group.background.color = \"#E5E1D8\",\n",
    "        table.font.size = 10,\n",
    "        heading.title.font.size = 20,\n",
    "        heading.subtitle.font.size = 12.5,\n",
    "        table.font.names = \"Consolas\", \n",
    "        data_row.padding = px(2)\n",
    "    ) %>% \n",
    "    tab_source_note(\n",
    "    source_note = \"Movement is calculated as adjusted rank - unadjusted rank\" ) %>% \n",
    "    tab_source_note(\n",
    "    source_note = \"@SravanNBA | Source: nba.com/stats\" ) %>% gtsave(\"../figs/team_leaders/Teams_aNET_movement.png\",zoom=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i results \n",
    "library(tidyverse)\n",
    "library(gt)\n",
    "df <- results\n",
    "df %>% \n",
    "  gt()%>%\n",
    "  # cols_move(OFF_R,OFF) %>% cols_move(DEF_R,DEF) %>% cols_move(NET_R,NET) %>%\n",
    "  # cols_move(aOFF_R,aOFF) %>% cols_move(aDEF_R,aDEF) %>% cols_move(aNET_R,aNET) %>%\n",
    "  tab_header(\n",
    "    title = md(\"**NBA Adjusted Net Rating Leaders 2023-24**\"),\n",
    "    subtitle = md(\"The Offensive, Defensive and Net Ratings are adjusted for Strength of Schedule\" )\n",
    "    ) %>%\n",
    "    data_color(columns = c(OFF,aOFF,NET,aNET), palette = c(\"red\", \"green\")) %>%\n",
    "    data_color(columns = c(DEF,aDEF), palette = c(\"green\",\"red\")) %>%\n",
    "    cols_align(align = \"center\",columns = c(OFF,DEF,NET,aOFF,aDEF,aNET))  %>%\n",
    "    cols_label(\n",
    "      OFF_R = \"#\",DEF_R = \"#\",NET_R = \"#\",aOFF_R = \"#\",aDEF_R = \"#\",aNET_R = \"#\"\n",
    "    ) %>%\n",
    "    tab_options(\n",
    "        table.background.color = \"floralwhite\",\n",
    "        column_labels.font.size = 12,\n",
    "        column_labels.font.weight = 'bold',\n",
    "        row_group.font.weight = 'bold',\n",
    "        row_group.background.color = \"#E5E1D8\",\n",
    "        table.font.size = 10,\n",
    "        heading.title.font.size = 20,\n",
    "        heading.subtitle.font.size = 12.5,\n",
    "        table.font.names = \"Consolas\", \n",
    "        data_row.padding = px(2)\n",
    "    ) %>% \n",
    "    tab_spanner(\n",
    "      label = \"Unadjusted\",\n",
    "      columns = c(OFF, OFF_R, DEF, DEF_R, NET, NET_R)\n",
    "    ) %>%\n",
    "    tab_spanner(\n",
    "      label = \"Adjusted\",\n",
    "      columns = c(aOFF, aOFF_R, aDEF, aDEF_R, aNET, aNET_R)\n",
    "    ) %>%\n",
    "    tab_source_note(\n",
    "    source_note = \"SOS adjustments done using Ridge Regression Method to estimate Off and Def Ratings\" ) %>% \n",
    "    tab_source_note(\n",
    "    source_note = \"@SravanNBA | Source: nba.com/stats\" ) %>% gtsave(\"../figs/team_leaders/Teams_aNET.png\",zoom=5) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-ub9Z_EQq-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
